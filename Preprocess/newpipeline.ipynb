{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READING FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS IS USED TO COMBINE SMALL AREAS:\n",
    "\n",
    "# # Read lookup for geographic hierarchy\n",
    "# tiers = pd.read_csv('./LAD_County_Region_Country_2021.csv')\n",
    "\n",
    "# # Combine small areas\n",
    "# tiers = tiers.append({'LAD21CD': 'E09000001/E09000033', 'LAD21NM': 'City of London/Westminster', 'CTY21CD': 'E13000001', 'CTY21NM': 'Inner London', 'RGN21CD': 'E12000007', 'RGN21NM': 'London', 'CTRY21CD': 'E92000001', 'CTRY21NM': 'England'}, ignore_index=True)\n",
    "\n",
    "# tiers = tiers.append({'LAD21CD': 'E06000052/E06000053', 'LAD21NM': 'Cornwall/Isles of Scilly', 'CTY21CD': 'E06000052/E06000053', 'CTY21NM': 'Cornwall/Isles of Scilly', 'RGN21CD': 'E12000009', 'RGN21NM': 'South West', 'CTRY21CD': 'E92000001', 'CTRY21NM': 'England'}, ignore_index=True)\n",
    "\n",
    "# # Remove the small areas (uncombined)\n",
    "# tiers = tiers[tiers['LAD21NM'].apply(lambda x: x not in ['Cornwall', 'Isles of Scilly', 'Westminster', 'City of London'])]\n",
    "\n",
    "# tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAD21CD</th>\n",
       "      <th>LAD21NM</th>\n",
       "      <th>CTY21CD</th>\n",
       "      <th>CTY21NM</th>\n",
       "      <th>RGN21CD</th>\n",
       "      <th>RGN21NM</th>\n",
       "      <th>CTRY21CD</th>\n",
       "      <th>CTRY21NM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E06000001</td>\n",
       "      <td>Hartlepool</td>\n",
       "      <td>E06000001</td>\n",
       "      <td>Hartlepool</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>North East</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E06000002</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>E06000002</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>North East</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E06000003</td>\n",
       "      <td>Redcar and Cleveland</td>\n",
       "      <td>E06000003</td>\n",
       "      <td>Redcar and Cleveland</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>North East</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E06000004</td>\n",
       "      <td>Stockton-on-Tees</td>\n",
       "      <td>E06000004</td>\n",
       "      <td>Stockton-on-Tees</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>North East</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E06000005</td>\n",
       "      <td>Darlington</td>\n",
       "      <td>E06000005</td>\n",
       "      <td>Darlington</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>North East</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>W06000020</td>\n",
       "      <td>Torfaen</td>\n",
       "      <td>W06000020</td>\n",
       "      <td>Torfaen</td>\n",
       "      <td>W92000004</td>\n",
       "      <td>Wales</td>\n",
       "      <td>W92000004</td>\n",
       "      <td>Wales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>W06000021</td>\n",
       "      <td>Monmouthshire</td>\n",
       "      <td>W06000021</td>\n",
       "      <td>Monmouthshire</td>\n",
       "      <td>W92000004</td>\n",
       "      <td>Wales</td>\n",
       "      <td>W92000004</td>\n",
       "      <td>Wales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>W06000022</td>\n",
       "      <td>Newport</td>\n",
       "      <td>W06000022</td>\n",
       "      <td>Newport</td>\n",
       "      <td>W92000004</td>\n",
       "      <td>Wales</td>\n",
       "      <td>W92000004</td>\n",
       "      <td>Wales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>W06000023</td>\n",
       "      <td>Powys</td>\n",
       "      <td>W06000023</td>\n",
       "      <td>Powys</td>\n",
       "      <td>W92000004</td>\n",
       "      <td>Wales</td>\n",
       "      <td>W92000004</td>\n",
       "      <td>Wales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>W06000024</td>\n",
       "      <td>Merthyr Tydfil</td>\n",
       "      <td>W06000024</td>\n",
       "      <td>Merthyr Tydfil</td>\n",
       "      <td>W92000004</td>\n",
       "      <td>Wales</td>\n",
       "      <td>W92000004</td>\n",
       "      <td>Wales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LAD21CD               LAD21NM    CTY21CD               CTY21NM  \\\n",
       "0    E06000001            Hartlepool  E06000001            Hartlepool   \n",
       "1    E06000002         Middlesbrough  E06000002         Middlesbrough   \n",
       "2    E06000003  Redcar and Cleveland  E06000003  Redcar and Cleveland   \n",
       "3    E06000004      Stockton-on-Tees  E06000004      Stockton-on-Tees   \n",
       "4    E06000005            Darlington  E06000005            Darlington   \n",
       "..         ...                   ...        ...                   ...   \n",
       "326  W06000020               Torfaen  W06000020               Torfaen   \n",
       "327  W06000021         Monmouthshire  W06000021         Monmouthshire   \n",
       "328  W06000022               Newport  W06000022               Newport   \n",
       "329  W06000023                 Powys  W06000023                 Powys   \n",
       "330  W06000024        Merthyr Tydfil  W06000024        Merthyr Tydfil   \n",
       "\n",
       "       RGN21CD     RGN21NM   CTRY21CD CTRY21NM  \n",
       "0    E12000001  North East  E92000001  England  \n",
       "1    E12000001  North East  E92000001  England  \n",
       "2    E12000001  North East  E92000001  England  \n",
       "3    E12000001  North East  E92000001  England  \n",
       "4    E12000001  North East  E92000001  England  \n",
       "..         ...         ...        ...      ...  \n",
       "326  W92000004       Wales  W92000004    Wales  \n",
       "327  W92000004       Wales  W92000004    Wales  \n",
       "328  W92000004       Wales  W92000004    Wales  \n",
       "329  W92000004       Wales  W92000004    Wales  \n",
       "330  W92000004       Wales  W92000004    Wales  \n",
       "\n",
       "[331 rows x 8 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read lookup for geographic hierarchy\n",
    "tiers = pd.read_csv('./LAD_County_Region_Country_2021.csv')\n",
    "\n",
    "tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open data files containing nearest neighbour information and process into dictionaries\n",
    "with open('ladsneighbours.json') as json_file:\n",
    "    lads_neigh_raw = json.load(json_file)\n",
    "lads_neigh = {}\n",
    "for i in lads_neigh_raw:\n",
    "    if (lads_neigh_raw[i][0]):\n",
    "        lads_neigh[i] = lads_neigh_raw[i][0][0]\n",
    "    else:\n",
    "        lads_neigh[i] = lads_neigh_raw[i][1]\n",
    "\n",
    "# # Add nearest neighbour for combined small areas Cornwall and Isles of Scilly and CoL/Westminster\n",
    "# lads_neigh['E06000052/E06000053'] = lads_neigh['E06000052']\n",
    "# lads_neigh['E09000001/E09000033'] = lads_neigh['E09000033']\n",
    "\n",
    "countyneighbourdf = pd.read_csv('countyboundaries.csv')\n",
    "county_neigh = {}\n",
    "for i in countyneighbourdf.index:\n",
    "    countycodelist = countyneighbourdf.iloc[i]['neighbours'].split(\",\")\n",
    "    countylengthlist = countyneighbourdf.iloc[i]['lengths'].split(\",\")\n",
    "    zipped = list(zip(countycodelist, countylengthlist))\n",
    "    zipped = [i for i in zipped if i[0][:3] != \"E08\"]\n",
    "    zipped = sorted(zipped, reverse=True, key= lambda x: int(x[1]))\n",
    "    county_neigh[countyneighbourdf.iloc[i]['CTYUA21CD']] = zipped[0][0]\n",
    "\n",
    "# Add nearest neighbours for met counties as they weren't included in boudary data\n",
    "county_neigh['E11000001'] = 'E10000017'\n",
    "county_neigh['E11000002'] = 'E10000017'\n",
    "county_neigh['E11000003'] = 'E10000007'\n",
    "county_neigh['E11000007'] = 'E06000057'\n",
    "county_neigh['E11000005'] = 'E10000031'\n",
    "county_neigh['E11000006'] = 'E10000023'\n",
    "county_neigh['E13000001'] = 'E13000002'\n",
    "county_neigh['E13000002'] = 'E13000001'\n",
    "\n",
    "# # Add nearest neighbour for combined Cornwall and Isles of Scilly\n",
    "# county_neigh['E06000052/E06000053'] = county_neigh['E06000052']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and process data on statistical similarity\n",
    "similars = {}\n",
    "similar_raw = pd.read_csv('./LAD_MAY_2021_EW_Adjacency_Matrix.csv')\n",
    "for i in similar_raw.index:\n",
    "    similars[similar_raw.iloc[i]['LAD21CD']] = [similar_raw.iloc[i]['LAD1CD'],similar_raw.iloc[i]['LAD2CD'],similar_raw.iloc[i]['LAD3CD'],similar_raw.iloc[i]['LAD4CD']]\n",
    "\n",
    "### THIS IS FOR COMBINED SMALL AREAS\n",
    "# similars['E06000052/E06000053'] = similars['E06000052']\n",
    "# similars['E09000001/E09000033'] = similars['E09000033']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE THE EMPTY OBJECTS FOR EACH PLACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to find a statistically similar area\n",
    "def get_similar(code):\n",
    "    # Create a list of similar areas\n",
    "    theseSimilars = similars[code]\n",
    "    # Get rid of NaNs for the list of similars\n",
    "    theseSimilars = [i for i in theseSimilars if i == i]\n",
    "\n",
    "    # Filter out codes for Scotland and NI\n",
    "    theseSimilars = [i for i in theseSimilars if i[0] not in ['S', 'N']]\n",
    "\n",
    "    # Remove small areas\n",
    "    theseSimilars = [i for i in theseSimilars if i not in ['E09000001', 'E09000033', 'E06000053', 'E06000052']]\n",
    "\n",
    "    # Create variable for most similar area\n",
    "    if len(theseSimilars) > 0:\n",
    "        similar = theseSimilars[0]\n",
    "    else:\n",
    "        similar = None\n",
    "\n",
    "    # If the most similar area is also the nearest area, then chose another area\n",
    "    if similar == las[nameLA]['near']:\n",
    "        # If there's at least two similar areas reselect area\n",
    "        if len(theseSimilars)>1:\n",
    "            similar = theseSimilars[1]\n",
    "        else:\n",
    "            similar = None\n",
    "\n",
    "    return similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and object to populate with each area's data\n",
    "las = {}\n",
    "counties = {}\n",
    "regions = {}\n",
    "countries = {}\n",
    "\n",
    "# Iterate throough index of LA df\n",
    "for i in tiers.index:\n",
    "\n",
    "    # Create a variable which is an iterated row of the df\n",
    "    row = tiers.loc[i]\n",
    "\n",
    "    # The name of the area attached to this row\n",
    "    nameLA = row['LAD21NM']\n",
    "    nameCounty = row['CTY21NM']\n",
    "    nameRegion = row['RGN21NM']\n",
    "    nameCountry = row['CTRY21NM']\n",
    "\n",
    "    # Add an object with name and code info and empty nested oobject for data\n",
    "    las[nameLA] = {}\n",
    "    las[nameLA]['name'] = nameLA\n",
    "    las[nameLA]['parent'] = {\n",
    "        'name': nameRegion,\n",
    "        'code': row['RGN21CD']\n",
    "    }\n",
    "    las[nameLA]['country'] = nameCountry\n",
    "    las[nameLA]['code'] = row['LAD21CD']\n",
    "    las[nameLA]['type'] = 'LAD'\n",
    "    las[nameLA]['data'] = {}\n",
    "\n",
    "    counties[nameCounty] = {}\n",
    "    counties[nameCounty]['name'] = nameCounty\n",
    "    counties[nameCounty]['parent'] = {\n",
    "        'name': nameRegion,\n",
    "        'code': row['RGN21CD']\n",
    "    }\n",
    "    counties[nameCounty]['country'] = nameCountry\n",
    "    counties[nameCounty]['code'] = row['CTY21CD']\n",
    "    counties[nameCounty]['near'] = county_neigh[row['CTY21CD']]\n",
    "    counties[nameCounty]['type'] = 'County'\n",
    "    counties[nameCounty]['data'] = {}\n",
    "\n",
    "    regions[nameRegion] = {}\n",
    "    regions[nameRegion]['name'] = nameRegion\n",
    "    regions[nameRegion]['parent'] = {\n",
    "        'name': nameCountry,\n",
    "        'code': row['CTRY21CD']\n",
    "    }\n",
    "    regions[nameRegion]['country'] = nameCountry\n",
    "    regions[nameRegion]['code'] = row['RGN21CD']\n",
    "    regions[nameRegion]['type'] = 'Region'\n",
    "    regions[nameRegion]['data'] = {}\n",
    "\n",
    "    countries[nameCountry] = {}\n",
    "    countries[nameCountry]['name'] = nameCountry\n",
    "    countries[nameCountry]['code'] = row['CTRY21CD']\n",
    "    countries[nameCountry]['type'] = 'Country'\n",
    "    countries[nameCountry]['data'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PROCESSING BEGINS BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIST OF ALL TOPICS AND BOTH YEARS\n",
    "topics = ['care',\n",
    " 'religion',\n",
    " 'ethnicity',\n",
    " 'health',\n",
    " 'economic',\n",
    " 'household',\n",
    " 'marital',\n",
    " 'hours',\n",
    " 'tenure',\n",
    " 'disability',\n",
    " 'national',\n",
    " 'welsh',\n",
    " 'population',\n",
    " 'density',\n",
    " 'age10yr',\n",
    " 'agemed']\n",
    "years = ['2011', '2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  FUNCTION NOT NEEDED UNLESS MERGING SMALL AREAS\n",
    "\n",
    "# def merge_small(df):\n",
    "#     cityolondon = df[df['Area Name'] == 'City of London']\n",
    "#     westmin = df[df['Area Name'] == 'Westminster']\n",
    "\n",
    "#     cityolondon = cityolondon.drop(['Area Code', 'Area Name'], axis=1)\n",
    "#     westmin = westmin.drop(['Area Code', 'Area Name'], axis=1)\n",
    "\n",
    "#     cityolondon = cityolondon.reset_index(drop=True)\n",
    "#     westmin = westmin.reset_index(drop=True)\n",
    "\n",
    "#     colandwest = cityolondon.add(westmin, fill_value=0)\n",
    "#     colandwest['Area Code'] = 'E09000001/E09000033'\n",
    "#     colandwest['Area Name'] = 'City of London/Westminster'\n",
    "\n",
    "#     df = df.append(colandwest)\n",
    "\n",
    "#     cornwall = df[df['Area Name'] == 'Cornwall']\n",
    "#     scilly = df[df['Area Name'] == 'Isles of Scilly']\n",
    "\n",
    "#     cornwall = cornwall.drop(['Area Code', 'Area Name'], axis=1)\n",
    "#     scilly = scilly.drop(['Area Code', 'Area Name'], axis=1)\n",
    "\n",
    "#     cornwall = cornwall.reset_index(drop=True)\n",
    "#     scilly = scilly.reset_index(drop=True)\n",
    "\n",
    "#     cornandscilly = cornwall.add(scilly, fill_value=0)\n",
    "#     cornandscilly['Area Code'] = 'E06000052/E06000053'\n",
    "#     cornandscilly['Area Name'] = 'Cornwall/Isles of Scilly'\n",
    "\n",
    "#     df = df.append(cornandscilly)\n",
    "\n",
    "#     df = df[df['Area Name'].apply(lambda x: x not in ['Westminster', 'City of London', 'Cornwall', 'Isles of Scilly'])]\n",
    "#     df = df.reset_index(drop=True)\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_combine = {\n",
    "    'care': {\n",
    "        \"noCare\": [\"Not a carer\"],\n",
    "        \"1to19hoursWeek\": [\"Yes, 9 hours a week or less\", \"Yes, 10 to 19 hours a week\"],\n",
    "        \"20to49hoursWeek\": [\"Yes, 20 to 34 hours a week\", \"Yes, 35 to 49 hours a week\"],\n",
    "        \"49PlushoursWeek\": [\"Yes, 50 or more hours a week\"]\n",
    "    },\n",
    "    'religion': {\n",
    "        'Noreligion': ['No religion'],\n",
    "        'Christian': ['Christian'],\n",
    "        'Buddhist': ['Buddhist'],\n",
    "        'Hindu': ['Hindu'],\n",
    "        'Jewish': ['Jewish'],\n",
    "        'Muslim': ['Muslim'],\n",
    "        'Sikh': ['Sikh'],\n",
    "        'Otherreligion': ['Other religion'],\n",
    "        'Notstated': ['Not stated']\n",
    "    },\n",
    "    'ethnicity': {\n",
    "        'asian': ['Asian, Asian British or Asian Welsh'],\n",
    "        'black': ['Black, Black British, Black Welsh, Carribean or African'],\n",
    "        'mixed': ['Mixed or Multiple ethnic groups'],\n",
    "        'white': ['White'],\n",
    "        'other': ['Other ethnic group']\n",
    "    },\n",
    "    'health': {\n",
    "        'good': ['Very good health', 'Good health'],\n",
    "        'fair': ['Fair health'],\n",
    "        'bad': ['Bad health', 'Very bad health']\n",
    "    },\n",
    "    'economic': {\n",
    "        'employee': ['Economically active (excluding full-time students): In employment: Employee: Part-time', 'Economically active (excluding full-time students): In employment: Employee: Full-time'],\n",
    "        'self-employed': ['Economically active (excluding full-time students): In employment: Self-employed: Part-time', 'Economically active (excluding full-time students): In employment: Self-employed: Full-time'],\n",
    "        'unemployed': ['Economically active: Unemployed: Not a full-time student'],\n",
    "        'student': ['Economically active: Full-time student'],\n",
    "        'inactive': ['Economically inactive: Retired', 'Economically inactive (including full-time students): Student', 'Economically inactive: Looking after home or family', 'Economically inactive: Long-term sick or disabled', 'Economically inactive: Other']\n",
    "    },\n",
    "    'household': {\n",
    "        'OnePerson': ['One person household: Aged 66 years and over', 'One person household: Other'],\n",
    "        '65andOver': ['Single family household: All aged 66 years and over'],\n",
    "        'Married_Household': ['Single family household: Married or civil partnership couple: No children', 'Single family household: Married or civil partnership couple: Dependent children', 'Single family household: Married or civil partnership couple: All children non-dependent'],\n",
    "        'Cohabiting': ['Single family household: Cohabiting couple family : No children', 'Single family household: Cohabiting couple family : With dependent children', 'Single family household: Cohabiting couple family : All children non-dependent'],\n",
    "        'LoneParent': ['Single family household: Lone parent family : With dependent children', 'Single family household: Lone parent family : All children non-dependent'],\n",
    "        'Other': ['Single family household: Other single family household: Other family composition'],\n",
    "        'MultipleFamily': ['Multiple-family household: With dependent children', 'Multiple-Family Household : Other, including all full-time students and all aged 66 years and over']\n",
    "    },\n",
    "    'marital': {\n",
    "        'Single': ['Single never married or in a civil partnership'],\n",
    "        'Married': ['Married or in a registered civil partnership'],\n",
    "        'Seperated': ['Separated (but still legally married or still legally in a civil partnership)', 'Divorced or civil partnership dissolved'],\n",
    "        'Widowed': ['Widowed or surviving civil partnership partner']\n",
    "    },\n",
    "    'hours': {\n",
    "        '1-15': ['Part-time: 15 hours or less worked'],\n",
    "        '16-30': ['Part-time: 16 to 30 hours worked'],\n",
    "        '31-48': ['Full-time: 31 to 48 hours worked'],\n",
    "        '49plus': ['Full-time: 49 or more hours worked'],\n",
    "    },\n",
    "    'tenure': {\n",
    "        'owned': ['Owned: Owns outright', 'Owned: Owns with a mortgage or loan'],\n",
    "        'shared_ownership': ['Shared ownership: Shared ownership'],\n",
    "        'rented_social': ['Social rented: Rents from council or Local Authority', 'Social rented: Other social rented'],\n",
    "        'rented_private': ['Private rented: Private landlord or letting agency', 'Private rented: Other private rented'],\n",
    "        'rent_free': ['Lives rent free']\n",
    "    },\n",
    "    'disability': {\n",
    "        'lot': ['Disabled under the Equality Act: Day-to-day activities limited a lot'],\n",
    "        'little': ['Disabled under the Equality Act: Day-to-day activities limited a little'],\n",
    "        'notDisabled': ['Not disabled under the Equality Act :Has long term physical or mental health condition but day-to-day activities are not limited', 'Not disabled under the Equality Act: No long term physical or mental health conditions'],\n",
    "    },\n",
    "    'national': {\n",
    "        'BritishOnly': ['British only identity'],\n",
    "        'EnglishOnly': ['English only identity'],\n",
    "        'EnglishBritishOnly': ['English and British only identity'],\n",
    "        'OtherUK': ['Welsh only identity', 'Welsh and British only identity', 'Scottish only identity', 'Scottish and British only identity', 'Northern Irish only identity', 'Northern Irish and British only identity', 'Cornish only identity', 'Cornish and British only identity', 'Any other combination of UK identities (UK only)', 'Irish only identity', 'Irish and at least one UK identity', 'Other identity and at least one UK identity'],\n",
    "        'Othernon-UK': ['Other identity only']\n",
    "    },\n",
    "    'welsh': {\n",
    "        'SpeaksWelsh': ['Speaks Welsh'],\n",
    "        'NoWelsh': [\"Doesn't speak Welsh\"]\n",
    "    },\n",
    "    'population': {\n",
    "        'Population': ['Population']\n",
    "    },\n",
    "    'density': {\n",
    "        'density': ['Density']\n",
    "    },\n",
    "    'age10yr':{\n",
    "        '0-9': ['0-9'],\n",
    "        '10-19': ['10-19'],\n",
    "        '20-29': ['20-29'],\n",
    "        '30-39': ['30-39'],\n",
    "        '40-49': ['40-49'],\n",
    "        '50-59': ['50-59'],\n",
    "        '60-69': ['60-69'],\n",
    "        '70-79': ['70-79'],\n",
    "        '80plus': ['80plus']\n",
    "    },\n",
    "    'agemed': {\n",
    "        'Median Age': ['Median Age']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object that will hold all the dfs for all las in an indexable way\n",
    "data_las = {}\n",
    "data_counties = {}\n",
    "data_regions = {}\n",
    "data_countries = {}\n",
    "\n",
    "for topic in topics:\n",
    "    for year in years:\n",
    "\n",
    "        # Read a csv\n",
    "        df = pd.read_csv(\"./\"+topic+\"_\"+year+\".csv\")\n",
    "\n",
    "        # loop through the variables related to this topic\n",
    "        for key in topic_combine[topic]:\n",
    "\n",
    "            series = df[topic_combine[topic][key][0]]\n",
    "            for col in topic_combine[topic][key][1:]:\n",
    "                series = series + df[col]\n",
    "            df[key] = series\n",
    "\n",
    "            # Create this list to avoid dropping columns where the name hasn't changed\n",
    "            columns_to_drop = [i for i in topic_combine[topic][key] if i not in list(topic_combine[topic].keys())]\n",
    "            df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "        # columns_renamed = {i: i.replace(\" \", \"\") for i in df.columns}\n",
    "        # columns_renamed['Area Code'] = 'Area Code'\n",
    "        # columns_renamed['Area Name'] = 'Area Name'\n",
    "                \n",
    "        # df.rename(columns=columns_renamed, inplace=True)\n",
    "\n",
    "        # For some reason some areas have an astrix in the title\n",
    "        # df['Area Name'] = df['Area Name'].str.replace(\"*\", \"\")\n",
    "        df['Area Name'] = df['Area Name'].str.replace(\"\\(Met County\\)\", \"\").str.replace(\"()\", \"\").str.strip() \n",
    "\n",
    "        # # Merge data for small areas\n",
    "        # df = merge_small(df)\n",
    "\n",
    "        # Create a df including only LAs\n",
    "        data_las[topic+\"_\"+year] = df[df['Area Name'].apply(lambda x: x in las.keys())]\n",
    "\n",
    "        # Create a df including only counties\n",
    "        data_counties[topic+\"_\"+year] = df[df['Area Name'].apply(lambda x: x in counties.keys())]\n",
    "\n",
    "        # Reformat Captialised textfor regions and countries\n",
    "        df['Area Name'] = df['Area Name'].apply(lambda x: x.title().replace(\" And \", \" and \").replace(\" Of \", \" of \"))\n",
    "\n",
    "        # Create df for regions\n",
    "        data_regions[topic+\"_\"+year] = df[df['Area Name'].apply(lambda x: x in regions.keys())]\n",
    "\n",
    "        # Create df for regions\n",
    "        data_countries[topic+\"_\"+year] = df[df['Area Name'].apply(lambda x: x in countries.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These variables hold the relevant data tables and the objects that will be populated with the data, indexible by \n",
    "geog_tables = {'las': data_las, 'counties': data_counties, 'regions': data_regions, 'countries': data_countries}\n",
    "geog_objects = {'las': las, 'counties': counties, 'regions': regions, 'countries': countries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_data(name, geog):\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    for topic in topics:\n",
    "\n",
    "        # Create object for this topic\n",
    "        data[topic] = {}\n",
    "        data[topic]['value'] = {}\n",
    "        data[topic]['perc'] = {}\n",
    "\n",
    "        for year in years:\n",
    "\n",
    "            # Find table corresponding to topic and year\n",
    "            table = geog_tables[geog][topic+'_'+year]\n",
    "\n",
    "            row = table[table['Area Name'] == name].iloc[0]\n",
    "\n",
    "            # Find the row of the table relating to the area of iteration\n",
    "            row = table[table['Area Name'] == name].iloc[0]\n",
    "\n",
    "            # Transform row into dictionary\n",
    "            row = row.to_dict()\n",
    "\n",
    "            # Delete unneeded values\n",
    "            del row['Area Code']\n",
    "            del row['Area Name']\n",
    "\n",
    "            # Translate numpy int into python int for json serialisation\n",
    "            row = {i: int(row[i]) for i in row}\n",
    "\n",
    "            # Assign to main data object\n",
    "            data[topic]['value'][year] = row\n",
    "\n",
    "            # Calculate percentages: this calcualtion assumes that each figure combines to make a total\n",
    "            perc = {i: float(round(row[i]/sum(row.values()), 5)) for i in row}\n",
    "            data[topic]['perc'][year] = perc\n",
    "\n",
    "        for value_perc in ['value', 'perc']:\n",
    "            # Calculate percentage point changes\n",
    "            ob2 = data[topic][value_perc]['2021']\n",
    "            ob1 = data[topic][value_perc]['2011']\n",
    "            percob = {i: float(round(ob2[i] - ob1[i], 5)) for i in ob2}\n",
    "            data[topic][value_perc]['change'] = percob\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDING VALUE AND PERC DATA FOR EACH TOPIC AND YEAR\n",
    "\n",
    "for name in las.keys():\n",
    "    las[name]['data'] = find_data(name, 'las')\n",
    "\n",
    "for name in counties.keys():\n",
    "    counties[name]['data'] = find_data(name, 'counties')\n",
    "\n",
    "for name in regions.keys():\n",
    "     regions[name]['data'] = find_data(name, 'regions')\n",
    "\n",
    "for name in countries.keys():\n",
    "     countries[name]['data'] = find_data(name, 'countries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-156"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A function that fixes false neg/pos middle values\n",
    "def reverse_rank(x, sample):\n",
    "    half_sample = sample/2\n",
    "    if (abs(x) > half_sample):\n",
    "        x = ( ( (np.sign(x)*-1) * (sample + 1)) + (x) )\n",
    "    return x\n",
    "\n",
    "reverse_rank(-156, 331)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in a raw index and outputs a rank\n",
    "def process_rank(raw_rank, group_size):\n",
    "    rank = raw_rank+1\n",
    "\n",
    "    rank = reverse_rank(rank, group_size)\n",
    "\n",
    "    return int(rank)\n",
    "\n",
    "def create_ranks(name, topic, geog, hier, value_perc):\n",
    "    places = geog_objects[geog]\n",
    "    ob = {}\n",
    "    for type in ['2011', '2021', 'change']:\n",
    "        ob[type] = {}\n",
    "        for var in places[name]['data'][topic][value_perc][type].keys():\n",
    "\n",
    "            # Find the value of the data that is being ranked\n",
    "            this_data = places[name]['data'][topic][value_perc][type][var]\n",
    "\n",
    "            # Create list of values. If regional rank then filter by areas that share the same parent or country\n",
    "            if hier == 'regional':\n",
    "                group_data = [places[i]['data'][topic][value_perc][type][var] for i in places if places[i]['parent']['name'] == places[name]['parent']['name']]\n",
    "            else:\n",
    "                group_data = [places[i]['data'][topic][value_perc][type][var] for i in places if places[i]['country'] == places[name]['country']]\n",
    "            group_size = len(group_data)\n",
    "\n",
    "            # Sort the data then find the index of the data point we are ranking\n",
    "            group_data.sort()\n",
    "            raw_rank = group_data.index(this_data)\n",
    "\n",
    "            # Process the index into a rank and add to the object that will be outputted\n",
    "            ob[type][var] = process_rank(raw_rank, group_size)\n",
    "            \n",
    "    return ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDING RANKS FOR EACH TOPIC AND YEAR - NOT NEEDED FOR REGIONS AND COUNTRIES\n",
    "\n",
    "for name in las.keys():\n",
    "    for topic in topics:\n",
    "        las[name]['data'][topic]['perc_rank'] = create_ranks(name, topic, 'las', 'national', 'perc')\n",
    "        las[name]['data'][topic]['perc_rank_local'] = create_ranks(name, topic, 'las', 'regional', 'perc')\n",
    "        las[name]['data'][topic]['value_rank'] = create_ranks(name, topic, 'las', 'national', 'value')\n",
    "        las[name]['data'][topic]['value_rank_local'] = create_ranks(name, topic, 'las', 'regional', 'value')\n",
    "\n",
    "\n",
    "for name in counties.keys():\n",
    "    for topic in topics:\n",
    "        counties[name]['data'][topic]['perc_rank'] = create_ranks(name, topic, 'counties', 'national', 'perc')\n",
    "        counties[name]['data'][topic]['perc_rank_local'] = create_ranks(name, topic, 'counties', 'regional', 'perc')\n",
    "        counties[name]['data'][topic]['value_rank'] = create_ranks(name, topic, 'counties', 'national', 'value')\n",
    "        counties[name]['data'][topic]['value_rank_local'] = create_ranks(name, topic, 'counties', 'regional', 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that finds the value for a variable in the areas ranked above and below this area\n",
    "def above_below_data(geog, place_name, topic, type):\n",
    "    place = geog[place_name]\n",
    "    ob = place['data'][topic][type]\n",
    "    parent = place['parent']['name']\n",
    "    country = place['country']\n",
    "    value_perc = type.split(\"_\")[0]\n",
    "    if 'local' in type:\n",
    "        sample = len([i for i in geog if (geog[i]['parent']['name'] == parent)])\n",
    "    else:\n",
    "        sample = len([i for i in geog if (geog[i]['country'] == country)])\n",
    "\n",
    "    above_below = {}\n",
    "\n",
    "    variables = ob['2021'].keys()\n",
    "    for variable in variables: \n",
    "        above_below[variable] = {}\n",
    "        rank = ob['2021'][variable]\n",
    "\n",
    "        # Find the rank above above below\n",
    "        above =  reverse_rank(rank-1, sample)\n",
    "        below = reverse_rank(rank+1, sample)\n",
    "\n",
    "        name_above = [i for i in geog if ((geog[i]['parent']['name'] == parent)|('local' not in type)) & (geog[i]['data'][topic][type]['2021'][variable]==above)]\n",
    "        if name_above:\n",
    "            name_above = name_above[0]\n",
    "            area_above = {'name': name_above, 'value': geog[name_above]['data'][topic][value_perc]['2021'][variable]}\n",
    "            above_below[variable]['above'] = area_above\n",
    "\n",
    "\n",
    "        name_below = [i for i in geog if ((geog[i]['parent']['name'] == parent)|('local' not in type)) & (geog[i]['data'][topic][type]['2021'][variable]==below)]\n",
    "        if name_below:\n",
    "            name_below = name_below[0]\n",
    "            area_below = {'name': name_below, 'value': geog[name_below]['data'][topic][value_perc]['2021'][variable]}\n",
    "            above_below[variable]['below'] = area_below\n",
    "\n",
    "    ob['above_below'] = above_below\n",
    "    return ob\n",
    "\n",
    "# above_below_data(las, 'Gateshead', 'care', type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the areas that had a higher proportion but now have a lower proportion for some variable\n",
    "def overtake_data(geog, place_name, topic, type):\n",
    "    place = geog[place_name]\n",
    "    ob = place['data'][topic][type]\n",
    "    parent = place['parent']['name']\n",
    "    country = place['country']\n",
    "    value_perc = type.split(\"_\")[0]\n",
    "\n",
    "    # Create a list of places that are included in our sample:\n",
    "    if 'local' in type:\n",
    "        sample = [i for i in geog if (geog[i]['parent']['name'] == parent)]\n",
    "    else:\n",
    "        sample = [i for i in geog if (geog[i]['country'] == country)]\n",
    "\n",
    "    overtake = {}\n",
    "\n",
    "    variables = ob['2021'].keys()\n",
    "    for variable in variables: \n",
    "\n",
    "        # Find the values for 2011 and 2021\n",
    "        value_2011 =  place['data'][topic][value_perc]['2011'][variable]\n",
    "        value_2021 =  place['data'][topic][value_perc]['2021'][variable]\n",
    "\n",
    "        # Create a list of places that had higher proportion in 2011\n",
    "        higher_2011 = [name for name in sample if (geog[name]['data'][topic][value_perc]['2011'][variable] > value_2011) ]\n",
    "\n",
    "        # Filter that list to only include places that were lower in 2021\n",
    "        overtaken = [name for name in higher_2011 if (geog[name]['data'][topic][value_perc]['2021'][variable] < value_2021) ]\n",
    "\n",
    "        overtake[variable] = overtaken\n",
    "\n",
    "    ob['overtake'] = overtake\n",
    "    return ob\n",
    "# overtake_data(las, 'Darlington', 'care', 'perc_rank_local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the highest and lowest scoring three areas for some variable\n",
    "def top_bottom_data(geog, place_name, topic, type):\n",
    "    place = geog[place_name]\n",
    "    ob = place['data'][topic][type]\n",
    "    parent = place['parent']['name']\n",
    "    country = place['country']\n",
    "    value_perc = type.split(\"_\")[0]\n",
    "\n",
    "    # Create a list of places that are included in our sample:\n",
    "    if 'local' in type:\n",
    "        sample = [i for i in geog if (geog[i]['parent']['name'] == parent)]\n",
    "    else:\n",
    "        sample = [i for i in geog if (geog[i]['country'] == country)]\n",
    "\n",
    "    top_bottom = {}\n",
    "    top_bottom_11 = {}\n",
    "\n",
    "    variables = ob['2021'].keys()\n",
    "    for variable in variables:\n",
    "\n",
    "        t_b_var = {}\n",
    "        t_b_var_11 = {}\n",
    "\n",
    "        for rank in [1,2,3,-3,-2,-1]:\n",
    "            name = [name for name in sample if geog[name]['data'][topic][type]['2021'][variable] == rank]\n",
    "            if name:\n",
    "                name = name[0]\n",
    "                # Find the values for 2011 and 2021\n",
    "                value_2011 =  geog[name]['data'][topic][value_perc]['2011'][variable]\n",
    "                value_2021 =  geog[name]['data'][topic][value_perc]['2021'][variable]\n",
    "                t_b_var[rank] = {'2011': value_2011, '2021': value_2021, 'name': name, 'change': value_2021-value_2011}\n",
    "\n",
    "            # Repeat for 2011 ranks\n",
    "            name = [name for name in sample if geog[name]['data'][topic][type]['2011'][variable] == rank]\n",
    "            if name:\n",
    "                name = name[0]\n",
    "                # Find the values for 2011 and 2021\n",
    "                value_2011 =  geog[name]['data'][topic][value_perc]['2011'][variable]\n",
    "                value_2021 =  geog[name]['data'][topic][value_perc]['2021'][variable]\n",
    "                t_b_var_11[rank] = {'2011': value_2011, '2021': value_2021, 'name': name, 'change': round(value_2021-value_2011, 5)}\n",
    "\n",
    "        top_bottom[variable] = t_b_var\n",
    "        top_bottom_11[variable] = t_b_var_11\n",
    "\n",
    "    ob['top_bottom'] = top_bottom\n",
    "    ob['top_bottom_11'] = top_bottom_11\n",
    "    return ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the additional information about associated ranking areas\n",
    "for place in las:\n",
    "    for topic in topics:\n",
    "        for type in ['perc_rank', 'perc_rank_local']:\n",
    "            las[place]['data'][topic][type] = above_below_data(las, place, topic, type)\n",
    "            las[place]['data'][topic][type] = overtake_data(las, place, topic, type)\n",
    "            las[place]['data'][topic][type] = top_bottom_data(las, place, topic, type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find each LA and county's near and similar areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is done after first iteration to point to other objects in dictionary\n",
    "for i in tiers.index:\n",
    "\n",
    "    # Create a variable which is an iterated row of the df\n",
    "    row = tiers.loc[i]\n",
    "\n",
    "    # The name of the area attached to this row\n",
    "    nameLA = row['LAD21NM']\n",
    "    nameCounty = row['CTY21NM']\n",
    "\n",
    "    # print(row['LAD21NM'])\n",
    "    # print(row['LAD21CD'])\n",
    "\n",
    "    # las[nameLA]['near'] = lads_neigh[row['LAD21CD']]\n",
    "    las[nameLA]['near'] = [las[i] for i in las if las[i]['code'] == lads_neigh[row['LAD21CD']]][0].copy()\n",
    "    # las[nameLA]['near']['near'] = 'confudsed'\n",
    "    las[nameLA]['near']['near'] = \"\"\n",
    "    del las[nameLA]['near']['near']\n",
    "    las[nameLA]['near']['similar'] = \"\"\n",
    "    del las[nameLA]['near']['similar']\n",
    "\n",
    "    # las[nameLA]['similar'] = get_similar(row['LAD21CD'])\n",
    "    if get_similar(row['LAD21CD']):\n",
    "        las[nameLA]['similar'] = [las[i] for i in las if las[i]['code'] == get_similar(row['LAD21CD'])][0].copy()\n",
    "        las[nameLA]['similar']['near'] = \"\"\n",
    "        del las[nameLA]['similar']['near']\n",
    "        las[nameLA]['similar']['similar'] = \"\"\n",
    "        del las[nameLA]['similar']['similar']\n",
    "\n",
    "    # counties[nameCounty]['near'] = county_neigh[row['CTY21CD']] \n",
    "    counties[nameCounty]['near'] = [counties[i] for i in counties if counties[i]['code'] == county_neigh[row['CTY21CD']]][0].copy()\n",
    "    counties[nameCounty]['near']['near'] = \"\"\n",
    "    del counties[nameCounty]['near']['near']\n",
    "    counties[nameCounty]['near']['similar'] = \"\"\n",
    "    del counties[nameCounty]['near']['similar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a piece of data which is used in the age band section\n",
    "\n",
    "for geography in [counties, las]:\n",
    "    for area_name in geography:\n",
    "        area = geography[area_name]\n",
    "        ageBandChange = sorted([(i, area['data']['age10yr']['value']['2021'][i]-area['data']['age10yr']['value']['2011'][i]) for i in area['data']['age10yr']['value']['2011'].keys()], reverse=True, key=lambda x: x[1])\n",
    "\n",
    "        # ageBandChange= [i for i in ageBandChange if i[0]!='all']\n",
    "        ageBandPos = sorted([i for i in ageBandChange if i[1]>0], reverse=True, key=lambda x: abs(x[1]))\n",
    "        ageBandNeg = sorted([i for i in ageBandChange if i[1]<0], reverse=True, key=lambda x: abs(x[1]))\n",
    "\n",
    "        area['data']['age10yr']['absChange'] = {}\n",
    "        area['data']['age10yr']['absChange']['pos'] = ageBandPos\n",
    "        area['data']['age10yr']['absChange']['neg'] = ageBandNeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is the story finding section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_variables = [\"NoWelsh\", \"16-30\", \"31-48\", \"Widowed\", \"65andOver\", \"Other\", \"MultiOther\", \"fair\", \"rent_free\", \"shared_ownership\",  \"female\", \"male\", \"inactive\", '1to19hoursWeek', \"Religionnotstated\", \"OtherUK\", \"Married_Household\"]\n",
    "\n",
    "# Add a stories array for each area\n",
    "for name in las:\n",
    "    place = las[name]\n",
    "    stories = []\n",
    "    for a in place['data'].keys():\n",
    "        for d in place['data'][a]['perc']['change'].keys():\n",
    "            if d not in excluded_variables:\n",
    "                if a in ['population', 'agemed']:\n",
    "                    b = 'value'\n",
    "                else:\n",
    "                    b = 'perc'\n",
    "                stories.append({\n",
    "                    'label': a+'_'+b+'_change'+'_'+d, \n",
    "                    'locRank': place['data'][a][b+'_rank_local']['change'][d], \n",
    "                    'natRank': place['data'][a][b+'_rank']['change'][d], \n",
    "                    '2011': place['data'][a][b]['2011'][d],\n",
    "                    '2021': place['data'][a][b]['2021'][d],\n",
    "                    'change': place['data'][a][b]['change'][d],\n",
    "                    'perc_cha': 100*(place['data'][a][b]['change'][d]/place['data'][a][b]['2011'][d])\n",
    "                })\n",
    "    place['stories'] = stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function which outputs 1.0 for any positive number and -1.0 for any negative number\n",
    "sign = lambda x: math.copysign(1, x)\n",
    "sign(-9.7)\n",
    "\n",
    "# A function which takes in a list of stories and combines the 'type' lists of any repeated variables and gets rid of the duplcate\n",
    "def combinestories(stories):\n",
    "    stories2 = []\n",
    "    for s in stories:\n",
    "        if s['label'] in [i['label'] for i in stories2]:\n",
    "            index = next((i for i, item in enumerate(stories2) if item['label'] == s['label']), -1)\n",
    "            stories2[index]['type'] = stories2[index]['type'] + s['type']\n",
    "        else:\n",
    "            stories2.append(s)\n",
    "\n",
    "    return stories2\n",
    "\n",
    "# Functions that find regional and national equivelent to a local data point\n",
    "def reg(story):\n",
    "    s=story['label'].split(\"_\")\n",
    "    if len(s)>4:\n",
    "        s[3] = s[3] + \"_\" + s[4]\n",
    "    return region['data'][s[0]][s[1]][s[2]][s[3]]\n",
    "\n",
    "def cou(i):\n",
    "    s=i['label'].split(\"_\")\n",
    "    if len(s)>4:\n",
    "        s[3] = s[3] + \"_\" + s[4]\n",
    "    return country['data'][s[0]][s[1]][s[2]][s[3]]\n",
    "\n",
    "def simi(i):\n",
    "    s=i['label'].split(\"_\")\n",
    "    if len(s)>4:\n",
    "        s[3] = s[3] + \"_\" + s[4]\n",
    "    return similar['data'][s[0]][s[1]][s[2]][s[3]]\n",
    "\n",
    "def near(i):\n",
    "    s=i['label'].split(\"_\")\n",
    "    if len(s)>4:\n",
    "        s[3] = s[3] + \"_\" + s[4]\n",
    "    return nearby['data'][s[0]][s[1]][s[2]][s[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in las:\n",
    "    place = las[name]\n",
    "    region = regions[place['parent']['name']]\n",
    "    country = countries[place['country']]\n",
    "    # Skip similar-area based stories if this LA doesn't have a similar area\n",
    "    if 'similar' in place:\n",
    "        similar = place['similar']\n",
    "    nearby = place['near']\n",
    "\n",
    "    # Create a list of objects ordered by the size of difference between regional and local change\n",
    "    regDiff = [(i, {'otherchange': reg(i), 'dif': i['change']-reg(i)}) for i in place['stories']]\n",
    "    couDiff = [(i, {'otherchange': cou(i), 'dif': i['change']-cou(i)}) for i in place['stories']]\n",
    "    if 'similar' in place:\n",
    "        simiDiff = [(i, {'otherchange': simi(i), 'dif': i['change']-simi(i)}) for i in place['stories']]\n",
    "    nearDiff = [(i, {'otherchange': near(i), 'dif': i['change']-near(i)}) for i in place['stories']]\n",
    "\n",
    "    # Create list of objects ordered by size of PP change\n",
    "    vallist = sorted(place['stories'], reverse=True, key=lambda x: x['change'])\n",
    "\n",
    "    # Iterate through vallist to find the largest percentage point increase for ethnicity and religion\n",
    "    ethStory = next(filter(lambda x: x['label'].split(\"_\")[0] == 'ethnicity', vallist))\n",
    "    relStory = next(filter(lambda x: x['label'].split(\"_\")[0] == 'religion', vallist))\n",
    "\n",
    "    # Add the story type descriptor for these two stories\n",
    "    ethStory = [{**ethStory, **{'type':['ethrel']}}]\n",
    "    relStory = [{**relStory, **{'type':['ethrel']}}]\n",
    "\n",
    "    # Remove all religion and ethnicity variables from our original story list and add the two stories pre-selected\n",
    "    place['stories'] = [i for i in place['stories'] if (i['label'].split(\"_\")[0]!='religion') & (i['label'].split(\"_\")[0]!='ethnicity')]+ethStory+relStory\n",
    "\n",
    "    # This records the story type for each variable in our stories list\n",
    "    stories = []\n",
    "    if (country['name']=='Wales'):\n",
    "        stories=stories+[{**i, **{'type':['welsh']}} for i in place['stories'] if i['label'] == 'welsh_perc_change_Speaks Welsh']\n",
    "    stories+[{**i, **{'type':['pop']}} for i in place['stories'] if i['label'] == 'population_value_change_Population']\n",
    "    stories=stories+[{**i, **{'type':['size']}} for i in place['stories'] if ((abs(i['change'])/abs(i['2011'])>0.2)&(abs(i['change']) > 1))]\n",
    "    stories=stories+[{**i, **{'type':['locRank']}} for i in place['stories'] if (abs(i['locRank']) < 4)&(abs(i['change']) > 0.5)]\n",
    "    stories=stories+[{**i, **{'type':['natRank']}} for i in place['stories'] if (abs(i['natRank']) < 4)&(abs(i['change']) > 0.5)]\n",
    "    stories=stories+[{**i[0], **{'type':['couBuck']}} for i in couDiff if ((abs(i[1]['otherchange'])>1) & (abs(i[0]['change'])>1) & (sign(i[1]['otherchange'])!=sign(i[0]['change'])))]\n",
    "    stories=stories+[{**i[0], **{'type':['regBuck']}} for i in regDiff if ((abs(i[1]['otherchange'])>1) & (abs(i[0]['change'])>1) & (sign(i[1]['otherchange'])!=sign(i[0]['change'])))]\n",
    "    stories=stories+[{**i[0], **{'type':['couDiff']}} for i in couDiff if ((abs(i[1]['dif'])>2) & (sign(i[1]['otherchange'])==sign(i[0]['change'])))]\n",
    "    stories=stories+[{**i[0], **{'type':['regDiff']}} for i in regDiff if ((abs(i[1]['dif'])>2) & (sign(i[1]['otherchange'])==sign(i[0]['change'])))]\n",
    "    stories=stories+[{**i[0], **{'type':['nearDiff']}} for i in nearDiff if ((abs(i[1]['dif'])>2) & (sign(i[1]['otherchange'])==sign(i[0]['change'])))]\n",
    "    if 'similar' in place:\n",
    "        stories=stories+[{**i[0], **{'type':['simiDiff']}} for i in simiDiff if ((abs(i[1]['dif'])>2) & (sign(i[1]['otherchange'])==sign(i[0]['change'])))]\n",
    "    stories=stories+[{**i, **{'type':['general']}} for i in place['stories']]\n",
    "    stories = combinestories(stories)\n",
    "\n",
    "    # This section puts stories in order based on how notable each variable is\n",
    "    stories = sorted(stories, reverse=True, key=lambda x: abs(x['locRank'])<4)\n",
    "    stories = sorted(stories, reverse=True, key=lambda x: abs(x['natRank'])<4)\n",
    "    stories = sorted(stories, reverse=True, key=lambda x: abs(x['locRank'])<3)\n",
    "    stories = sorted(stories, reverse=True, key=lambda x: abs(x['natRank'])<3)\n",
    "    stories = sorted(stories, reverse=True, key=lambda x: x['type']=='regBuck')\n",
    "    stories = sorted(stories, reverse=True, key=lambda x: x['type']=='couBuck')\n",
    "    stories = sorted(stories, reverse=True, key=lambda x: x['label']=='welsh_perc_change_Speaks Welsh')\n",
    "    stories = sorted(stories, reverse=True, key=lambda x: x['label']=='agemed_value_change_Median Age')\n",
    "    stories = sorted(stories, reverse=True, key=lambda x: x['label']=='population_value_change_Population')\n",
    "\n",
    "    # Remove stories from topics that have appeared higher up in the story list\n",
    "    stories_uniquetopic = []\n",
    "    dontInc = ['density', 'age10yr']\n",
    "    for story in stories:\n",
    "        if story['label'].split(\"_\")[0] not in dontInc:\n",
    "            stories_uniquetopic.append(story)\n",
    "            dontInc.append(story['label'].split(\"_\")[0])\n",
    "\n",
    "    place['stories'] = stories_uniquetopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'North West',\n",
       " 'parent': {'name': 'England', 'code': 'E92000001'},\n",
       " 'country': 'England',\n",
       " 'code': 'E12000002',\n",
       " 'type': 'Region',\n",
       " 'data': {'care': {'value': {'2011': {'noCare': 40411,\n",
       "     '1to19hoursWeek': 92771,\n",
       "     '20to49hoursWeek': 91479,\n",
       "     '49PlushoursWeek': 24883},\n",
       "    '2021': {'noCare': 63342,\n",
       "     '1to19hoursWeek': 65543,\n",
       "     '20to49hoursWeek': 113458,\n",
       "     '49PlushoursWeek': 36744},\n",
       "    'change': {'noCare': 22931.0,\n",
       "     '1to19hoursWeek': -27228.0,\n",
       "     '20to49hoursWeek': 21979.0,\n",
       "     '49PlushoursWeek': 11861.0}},\n",
       "   'perc': {'2011': {'noCare': 0.16194,\n",
       "     '1to19hoursWeek': 0.37176,\n",
       "     '20to49hoursWeek': 0.36658,\n",
       "     '49PlushoursWeek': 0.09971},\n",
       "    '2021': {'noCare': 0.22696,\n",
       "     '1to19hoursWeek': 0.23485,\n",
       "     '20to49hoursWeek': 0.40653,\n",
       "     '49PlushoursWeek': 0.13166},\n",
       "    'change': {'noCare': 0.06502,\n",
       "     '1to19hoursWeek': -0.13691,\n",
       "     '20to49hoursWeek': 0.03995,\n",
       "     '49PlushoursWeek': 0.03195}}},\n",
       "  'religion': {'value': {'2011': {'Christian': 97040,\n",
       "     'Buddhist': 40764,\n",
       "     'Hindu': 72688,\n",
       "     'Jewish': 40899,\n",
       "     'Muslim': 18672,\n",
       "     'Sikh': 59994,\n",
       "     'Noreligion': 20770,\n",
       "     'Otherreligion': 79443,\n",
       "     'Notstated': 80953},\n",
       "    '2021': {'Christian': 76632,\n",
       "     'Buddhist': 26244,\n",
       "     'Hindu': 84014,\n",
       "     'Jewish': 27463,\n",
       "     'Muslim': 25509,\n",
       "     'Sikh': 45913,\n",
       "     'Noreligion': 16993,\n",
       "     'Otherreligion': 52394,\n",
       "     'Notstated': 95599},\n",
       "    'change': {'Christian': -20408.0,\n",
       "     'Buddhist': -14520.0,\n",
       "     'Hindu': 11326.0,\n",
       "     'Jewish': -13436.0,\n",
       "     'Muslim': 6837.0,\n",
       "     'Sikh': -14081.0,\n",
       "     'Noreligion': -3777.0,\n",
       "     'Otherreligion': -27049.0,\n",
       "     'Notstated': 14646.0}},\n",
       "   'perc': {'2011': {'Christian': 0.18982,\n",
       "     'Buddhist': 0.07974,\n",
       "     'Hindu': 0.14218,\n",
       "     'Jewish': 0.08,\n",
       "     'Muslim': 0.03652,\n",
       "     'Sikh': 0.11735,\n",
       "     'Noreligion': 0.04063,\n",
       "     'Otherreligion': 0.1554,\n",
       "     'Notstated': 0.15835},\n",
       "    '2021': {'Christian': 0.17001,\n",
       "     'Buddhist': 0.05822,\n",
       "     'Hindu': 0.18638,\n",
       "     'Jewish': 0.06093,\n",
       "     'Muslim': 0.05659,\n",
       "     'Sikh': 0.10186,\n",
       "     'Noreligion': 0.0377,\n",
       "     'Otherreligion': 0.11623,\n",
       "     'Notstated': 0.21208},\n",
       "    'change': {'Christian': -0.01981,\n",
       "     'Buddhist': -0.02152,\n",
       "     'Hindu': 0.0442,\n",
       "     'Jewish': -0.01907,\n",
       "     'Muslim': 0.02007,\n",
       "     'Sikh': -0.01549,\n",
       "     'Noreligion': -0.00293,\n",
       "     'Otherreligion': -0.03917,\n",
       "     'Notstated': 0.05373}}},\n",
       "  'ethnicity': {'value': {'2011': {'asian': 42083,\n",
       "     'black': 73963,\n",
       "     'mixed': 20117,\n",
       "     'white': 76341,\n",
       "     'other': 14909},\n",
       "    '2021': {'asian': 62658,\n",
       "     'black': 94881,\n",
       "     'mixed': 17756,\n",
       "     'white': 96174,\n",
       "     'other': 10117},\n",
       "    'change': {'asian': 20575.0,\n",
       "     'black': 20918.0,\n",
       "     'mixed': -2361.0,\n",
       "     'white': 19833.0,\n",
       "     'other': -4792.0}},\n",
       "   'perc': {'2011': {'asian': 0.18505,\n",
       "     'black': 0.32524,\n",
       "     'mixed': 0.08846,\n",
       "     'white': 0.33569,\n",
       "     'other': 0.06556},\n",
       "    '2021': {'asian': 0.22252,\n",
       "     'black': 0.33695,\n",
       "     'mixed': 0.06306,\n",
       "     'white': 0.34154,\n",
       "     'other': 0.03593},\n",
       "    'change': {'asian': 0.03747,\n",
       "     'black': 0.01171,\n",
       "     'mixed': -0.0254,\n",
       "     'white': 0.00585,\n",
       "     'other': -0.02963}}},\n",
       "  'health': {'value': {'2011': {'good': 9849, 'fair': 60532, 'bad': 101664},\n",
       "    '2021': {'good': 9375, 'fair': 66031, 'bad': 80997},\n",
       "    'change': {'good': -474.0, 'fair': 5499.0, 'bad': -20667.0}},\n",
       "   'perc': {'2011': {'good': 0.05725, 'fair': 0.35184, 'bad': 0.59092},\n",
       "    '2021': {'good': 0.05994, 'fair': 0.42218, 'bad': 0.51787},\n",
       "    'change': {'good': 0.00269, 'fair': 0.07034, 'bad': -0.07305}}},\n",
       "  'economic': {'value': {'2011': {'employee': 29048,\n",
       "     'self-employed': 102575,\n",
       "     'unemployed': 19503,\n",
       "     'student': 33242,\n",
       "     'inactive': 209770},\n",
       "    '2021': {'employee': 25885,\n",
       "     'self-employed': 93125,\n",
       "     'unemployed': 16389,\n",
       "     'student': 51279,\n",
       "     'inactive': 213321},\n",
       "    'change': {'employee': -3163.0,\n",
       "     'self-employed': -9450.0,\n",
       "     'unemployed': -3114.0,\n",
       "     'student': 18037.0,\n",
       "     'inactive': 3551.0}},\n",
       "   'perc': {'2011': {'employee': 0.0737,\n",
       "     'self-employed': 0.26025,\n",
       "     'unemployed': 0.04948,\n",
       "     'student': 0.08434,\n",
       "     'inactive': 0.53222},\n",
       "    '2021': {'employee': 0.06471,\n",
       "     'self-employed': 0.23281,\n",
       "     'unemployed': 0.04097,\n",
       "     'student': 0.1282,\n",
       "     'inactive': 0.5333},\n",
       "    'change': {'employee': -0.00899,\n",
       "     'self-employed': -0.02744,\n",
       "     'unemployed': -0.00851,\n",
       "     'student': 0.04386,\n",
       "     'inactive': 0.00108}}},\n",
       "  'household': {'value': {'2011': {'OnePerson': 111673,\n",
       "     '65andOver': 18584,\n",
       "     'Married_Household': 259993,\n",
       "     'Cohabiting': 163712,\n",
       "     'LoneParent': 149864,\n",
       "     'Other': 91432,\n",
       "     'MultipleFamily': 196361},\n",
       "    '2021': {'OnePerson': 155169,\n",
       "     '65andOver': 24452,\n",
       "     'Married_Household': 254062,\n",
       "     'Cohabiting': 218159,\n",
       "     'LoneParent': 206688,\n",
       "     'Other': 77274,\n",
       "     'MultipleFamily': 217149},\n",
       "    'change': {'OnePerson': 43496.0,\n",
       "     '65andOver': 5868.0,\n",
       "     'Married_Household': -5931.0,\n",
       "     'Cohabiting': 54447.0,\n",
       "     'LoneParent': 56824.0,\n",
       "     'Other': -14158.0,\n",
       "     'MultipleFamily': 20788.0}},\n",
       "   'perc': {'2011': {'OnePerson': 0.11262,\n",
       "     '65andOver': 0.01874,\n",
       "     'Married_Household': 0.26219,\n",
       "     'Cohabiting': 0.1651,\n",
       "     'LoneParent': 0.15113,\n",
       "     'Other': 0.0922,\n",
       "     'MultipleFamily': 0.19802},\n",
       "    '2021': {'OnePerson': 0.13458,\n",
       "     '65andOver': 0.02121,\n",
       "     'Married_Household': 0.22036,\n",
       "     'Cohabiting': 0.18922,\n",
       "     'LoneParent': 0.17927,\n",
       "     'Other': 0.06702,\n",
       "     'MultipleFamily': 0.18834},\n",
       "    'change': {'OnePerson': 0.02196,\n",
       "     '65andOver': 0.00247,\n",
       "     'Married_Household': -0.04183,\n",
       "     'Cohabiting': 0.02412,\n",
       "     'LoneParent': 0.02814,\n",
       "     'Other': -0.02518,\n",
       "     'MultipleFamily': -0.00968}}},\n",
       "  'marital': {'value': {'2011': {'Single': 35691,\n",
       "     'Married': 55468,\n",
       "     'Seperated': 100356,\n",
       "     'Widowed': 50966},\n",
       "    '2021': {'Single': 33598,\n",
       "     'Married': 61121,\n",
       "     'Seperated': 76897,\n",
       "     'Widowed': 68980},\n",
       "    'change': {'Single': -2093.0,\n",
       "     'Married': 5653.0,\n",
       "     'Seperated': -23459.0,\n",
       "     'Widowed': 18014.0}},\n",
       "   'perc': {'2011': {'Single': 0.14719,\n",
       "     'Married': 0.22875,\n",
       "     'Seperated': 0.41387,\n",
       "     'Widowed': 0.21019},\n",
       "    '2021': {'Single': 0.13964,\n",
       "     'Married': 0.25404,\n",
       "     'Seperated': 0.31961,\n",
       "     'Widowed': 0.2867},\n",
       "    'change': {'Single': -0.00755,\n",
       "     'Married': 0.02529,\n",
       "     'Seperated': -0.09426,\n",
       "     'Widowed': 0.07651}}},\n",
       "  'hours': {'value': {'2011': {'1-15': 76888,\n",
       "     '16-30': 45181,\n",
       "     '31-48': 39519,\n",
       "     '49plus': 44513},\n",
       "    '2021': {'1-15': 105576, '16-30': 43283, '31-48': 35697, '49plus': 38344},\n",
       "    'change': {'1-15': 28688.0,\n",
       "     '16-30': -1898.0,\n",
       "     '31-48': -3822.0,\n",
       "     '49plus': -6169.0}},\n",
       "   'perc': {'2011': {'1-15': 0.37306,\n",
       "     '16-30': 0.21922,\n",
       "     '31-48': 0.19175,\n",
       "     '49plus': 0.21598},\n",
       "    '2021': {'1-15': 0.47365,\n",
       "     '16-30': 0.19418,\n",
       "     '31-48': 0.16015,\n",
       "     '49plus': 0.17202},\n",
       "    'change': {'1-15': 0.10059,\n",
       "     '16-30': -0.02504,\n",
       "     '31-48': -0.0316,\n",
       "     '49plus': -0.04396}}},\n",
       "  'tenure': {'value': {'2011': {'owned': 81397,\n",
       "     'shared_ownership': 76238,\n",
       "     'rented_social': 116023,\n",
       "     'rented_private': 86477,\n",
       "     'rent_free': 85178},\n",
       "    '2021': {'owned': 109382,\n",
       "     'shared_ownership': 114686,\n",
       "     'rented_social': 128920,\n",
       "     'rented_private': 89535,\n",
       "     'rent_free': 101763},\n",
       "    'change': {'owned': 27985.0,\n",
       "     'shared_ownership': 38448.0,\n",
       "     'rented_social': 12897.0,\n",
       "     'rented_private': 3058.0,\n",
       "     'rent_free': 16585.0}},\n",
       "   'perc': {'2011': {'owned': 0.18279,\n",
       "     'shared_ownership': 0.1712,\n",
       "     'rented_social': 0.26054,\n",
       "     'rented_private': 0.19419,\n",
       "     'rent_free': 0.19128},\n",
       "    '2021': {'owned': 0.20096,\n",
       "     'shared_ownership': 0.21071,\n",
       "     'rented_social': 0.23686,\n",
       "     'rented_private': 0.1645,\n",
       "     'rent_free': 0.18697},\n",
       "    'change': {'owned': 0.01817,\n",
       "     'shared_ownership': 0.03951,\n",
       "     'rented_social': -0.02368,\n",
       "     'rented_private': -0.02969,\n",
       "     'rent_free': -0.00431}}},\n",
       "  'disability': {'value': {'2011': {'lot': 22194,\n",
       "     'little': 51268,\n",
       "     'notDisabled': 43351},\n",
       "    '2021': {'lot': 24231, 'little': 64147, 'notDisabled': 42253},\n",
       "    'change': {'lot': 2037.0, 'little': 12879.0, 'notDisabled': -1098.0}},\n",
       "   'perc': {'2011': {'lot': 0.19, 'little': 0.43889, 'notDisabled': 0.37111},\n",
       "    '2021': {'lot': 0.18549, 'little': 0.49105, 'notDisabled': 0.32345},\n",
       "    'change': {'lot': -0.00451, 'little': 0.05216, 'notDisabled': -0.04766}}},\n",
       "  'national': {'value': {'2011': {'BritishOnly': 66469,\n",
       "     'EnglishOnly': 29633,\n",
       "     'EnglishBritishOnly': 6482,\n",
       "     'OtherUK': 627345,\n",
       "     'Othernon-UK': 90203},\n",
       "    '2021': {'BritishOnly': 52454,\n",
       "     'EnglishOnly': 35459,\n",
       "     'EnglishBritishOnly': 6232,\n",
       "     'OtherUK': 776379,\n",
       "     'Othernon-UK': 57307},\n",
       "    'change': {'BritishOnly': -14015.0,\n",
       "     'EnglishOnly': 5826.0,\n",
       "     'EnglishBritishOnly': -250.0,\n",
       "     'OtherUK': 149034.0,\n",
       "     'Othernon-UK': -32896.0}},\n",
       "   'perc': {'2011': {'BritishOnly': 0.08105,\n",
       "     'EnglishOnly': 0.03613,\n",
       "     'EnglishBritishOnly': 0.0079,\n",
       "     'OtherUK': 0.76493,\n",
       "     'Othernon-UK': 0.10999},\n",
       "    '2021': {'BritishOnly': 0.05653,\n",
       "     'EnglishOnly': 0.03822,\n",
       "     'EnglishBritishOnly': 0.00672,\n",
       "     'OtherUK': 0.83677,\n",
       "     'Othernon-UK': 0.06176},\n",
       "    'change': {'BritishOnly': -0.02452,\n",
       "     'EnglishOnly': 0.00209,\n",
       "     'EnglishBritishOnly': -0.00118,\n",
       "     'OtherUK': 0.07184,\n",
       "     'Othernon-UK': -0.04823}}},\n",
       "  'welsh': {'value': {'2011': {'SpeaksWelsh': 52278, 'NoWelsh': 69803},\n",
       "    '2021': {'SpeaksWelsh': 33764, 'NoWelsh': 83322},\n",
       "    'change': {'SpeaksWelsh': -18514.0, 'NoWelsh': 13519.0}},\n",
       "   'perc': {'2011': {'SpeaksWelsh': 0.42822, 'NoWelsh': 0.57178},\n",
       "    '2021': {'SpeaksWelsh': 0.28837, 'NoWelsh': 0.71163},\n",
       "    'change': {'SpeaksWelsh': -0.13985, 'NoWelsh': 0.13985}}},\n",
       "  'population': {'value': {'2011': {'Population': 17747},\n",
       "    '2021': {'Population': 24343},\n",
       "    'change': {'Population': 6596.0}},\n",
       "   'perc': {'2011': {'Population': 1.0},\n",
       "    '2021': {'Population': 1.0},\n",
       "    'change': {'Population': 0.0}}},\n",
       "  'density': {'value': {'2011': {'density': 61593},\n",
       "    '2021': {'density': 63131},\n",
       "    'change': {'density': 1538.0}},\n",
       "   'perc': {'2011': {'density': 1.0},\n",
       "    '2021': {'density': 1.0},\n",
       "    'change': {'density': 0.0}}},\n",
       "  'age10yr': {'value': {'2011': {'0-9': 40682,\n",
       "     '10-19': 44505,\n",
       "     '20-29': 10334,\n",
       "     '30-39': 90318,\n",
       "     '40-49': 10481,\n",
       "     '50-59': 69866,\n",
       "     '60-69': 2753,\n",
       "     '70-79': 29916,\n",
       "     '80plus': 80149},\n",
       "    '2021': {'0-9': 28651,\n",
       "     '10-19': 47378,\n",
       "     '20-29': 16223,\n",
       "     '30-39': 140318,\n",
       "     '40-49': 14154,\n",
       "     '50-59': 82355,\n",
       "     '60-69': 2166,\n",
       "     '70-79': 42475,\n",
       "     '80plus': 115564},\n",
       "    'change': {'0-9': -12031.0,\n",
       "     '10-19': 2873.0,\n",
       "     '20-29': 5889.0,\n",
       "     '30-39': 50000.0,\n",
       "     '40-49': 3673.0,\n",
       "     '50-59': 12489.0,\n",
       "     '60-69': -587.0,\n",
       "     '70-79': 12559.0,\n",
       "     '80plus': 35415.0}},\n",
       "   'perc': {'2011': {'0-9': 0.10734,\n",
       "     '10-19': 0.11743,\n",
       "     '20-29': 0.02727,\n",
       "     '30-39': 0.2383,\n",
       "     '40-49': 0.02765,\n",
       "     '50-59': 0.18434,\n",
       "     '60-69': 0.00726,\n",
       "     '70-79': 0.07893,\n",
       "     '80plus': 0.21147},\n",
       "    '2021': {'0-9': 0.05856,\n",
       "     '10-19': 0.09683,\n",
       "     '20-29': 0.03316,\n",
       "     '30-39': 0.28678,\n",
       "     '40-49': 0.02893,\n",
       "     '50-59': 0.16832,\n",
       "     '60-69': 0.00443,\n",
       "     '70-79': 0.08681,\n",
       "     '80plus': 0.23619},\n",
       "    'change': {'0-9': -0.04878,\n",
       "     '10-19': -0.0206,\n",
       "     '20-29': 0.00589,\n",
       "     '30-39': 0.04848,\n",
       "     '40-49': 0.00128,\n",
       "     '50-59': -0.01602,\n",
       "     '60-69': -0.00283,\n",
       "     '70-79': 0.00788,\n",
       "     '80plus': 0.02472}}},\n",
       "  'agemed': {'value': {'2011': {'Median Age': 77359},\n",
       "    '2021': {'Median Age': 100130},\n",
       "    'change': {'Median Age': 22771.0}},\n",
       "   'perc': {'2011': {'Median Age': 1.0},\n",
       "    '2021': {'Median Age': 1.0},\n",
       "    'change': {'Median Age': 0.0}}}}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions['North West']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT DATA\n",
    "for region in regions:\n",
    "    try:\n",
    "        with open('../static/data/json_new/place/'+regions[region]['code']+'.json', 'w') as outfile:\n",
    "            json.dump(regions[region], outfile)\n",
    "    except:\n",
    "        print(\"Failed: \", regions[region]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in countries:\n",
    "    try:\n",
    "        with open('../static/data/json_new/place/'+countries[country]['code']+'.json', 'w') as outfile:\n",
    "            json.dump(countries[country], outfile)\n",
    "    except:\n",
    "        print(\"Failed: \", countries[country]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for la in las:\n",
    "    try:\n",
    "        with open('../static/data/json_new/place/'+las[la]['code']+'.json', 'w') as outfile:\n",
    "            json.dump(las[la], outfile)\n",
    "    except:\n",
    "        print(\"Failed: \", las[la]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c3aa89ca4d209c971de495120129cb3d674e54ab86ac569af1bfb76a7040f0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
