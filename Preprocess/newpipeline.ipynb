{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READING FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAD21CD</th>\n",
       "      <th>LAD21NM</th>\n",
       "      <th>CTY21CD</th>\n",
       "      <th>CTY21NM</th>\n",
       "      <th>RGN21CD</th>\n",
       "      <th>RGN21NM</th>\n",
       "      <th>CTRY21CD</th>\n",
       "      <th>CTRY21NM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E06000001</td>\n",
       "      <td>Hartlepool</td>\n",
       "      <td>E06000001</td>\n",
       "      <td>Hartlepool</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>North East</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E06000002</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>E06000002</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>North East</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E06000003</td>\n",
       "      <td>Redcar and Cleveland</td>\n",
       "      <td>E06000003</td>\n",
       "      <td>Redcar and Cleveland</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>North East</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E06000004</td>\n",
       "      <td>Stockton-on-Tees</td>\n",
       "      <td>E06000004</td>\n",
       "      <td>Stockton-on-Tees</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>North East</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E06000005</td>\n",
       "      <td>Darlington</td>\n",
       "      <td>E06000005</td>\n",
       "      <td>Darlington</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>North East</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>W06000022</td>\n",
       "      <td>Newport</td>\n",
       "      <td>W06000022</td>\n",
       "      <td>Newport</td>\n",
       "      <td>W92000004</td>\n",
       "      <td>Wales</td>\n",
       "      <td>W92000004</td>\n",
       "      <td>Wales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>W06000023</td>\n",
       "      <td>Powys</td>\n",
       "      <td>W06000023</td>\n",
       "      <td>Powys</td>\n",
       "      <td>W92000004</td>\n",
       "      <td>Wales</td>\n",
       "      <td>W92000004</td>\n",
       "      <td>Wales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>W06000024</td>\n",
       "      <td>Merthyr Tydfil</td>\n",
       "      <td>W06000024</td>\n",
       "      <td>Merthyr Tydfil</td>\n",
       "      <td>W92000004</td>\n",
       "      <td>Wales</td>\n",
       "      <td>W92000004</td>\n",
       "      <td>Wales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>E09000001/E09000033</td>\n",
       "      <td>City of London/Westminster</td>\n",
       "      <td>E13000001</td>\n",
       "      <td>Inner London</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>London</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>E06000052/E06000053</td>\n",
       "      <td>Cornwall/Isles of Scilly</td>\n",
       "      <td>E06000052/E06000053</td>\n",
       "      <td>Cornwall/Isles of Scilly</td>\n",
       "      <td>E12000009</td>\n",
       "      <td>South West</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 LAD21CD                     LAD21NM              CTY21CD  \\\n",
       "0              E06000001                  Hartlepool            E06000001   \n",
       "1              E06000002               Middlesbrough            E06000002   \n",
       "2              E06000003        Redcar and Cleveland            E06000003   \n",
       "3              E06000004            Stockton-on-Tees            E06000004   \n",
       "4              E06000005                  Darlington            E06000005   \n",
       "..                   ...                         ...                  ...   \n",
       "328            W06000022                     Newport            W06000022   \n",
       "329            W06000023                       Powys            W06000023   \n",
       "330            W06000024              Merthyr Tydfil            W06000024   \n",
       "331  E09000001/E09000033  City of London/Westminster            E13000001   \n",
       "332  E06000052/E06000053    Cornwall/Isles of Scilly  E06000052/E06000053   \n",
       "\n",
       "                      CTY21NM    RGN21CD     RGN21NM   CTRY21CD CTRY21NM  \n",
       "0                  Hartlepool  E12000001  North East  E92000001  England  \n",
       "1               Middlesbrough  E12000001  North East  E92000001  England  \n",
       "2        Redcar and Cleveland  E12000001  North East  E92000001  England  \n",
       "3            Stockton-on-Tees  E12000001  North East  E92000001  England  \n",
       "4                  Darlington  E12000001  North East  E92000001  England  \n",
       "..                        ...        ...         ...        ...      ...  \n",
       "328                   Newport  W92000004       Wales  W92000004    Wales  \n",
       "329                     Powys  W92000004       Wales  W92000004    Wales  \n",
       "330            Merthyr Tydfil  W92000004       Wales  W92000004    Wales  \n",
       "331              Inner London  E12000007      London  E92000001  England  \n",
       "332  Cornwall/Isles of Scilly  E12000009  South West  E92000001  England  \n",
       "\n",
       "[329 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read lookup for geographic hierarchy\n",
    "tiers = pd.read_csv('./LAD_County_Region_Country_2021.csv')\n",
    "\n",
    "# Combine small areas\n",
    "tiers = tiers.append({'LAD21CD': 'E09000001/E09000033', 'LAD21NM': 'City of London/Westminster', 'CTY21CD': 'E13000001', 'CTY21NM': 'Inner London', 'RGN21CD': 'E12000007', 'RGN21NM': 'London', 'CTRY21CD': 'E92000001', 'CTRY21NM': 'England'}, ignore_index=True)\n",
    "\n",
    "tiers = tiers.append({'LAD21CD': 'E06000052/E06000053', 'LAD21NM': 'Cornwall/Isles of Scilly', 'CTY21CD': 'E06000052/E06000053', 'CTY21NM': 'Cornwall/Isles of Scilly', 'RGN21CD': 'E12000009', 'RGN21NM': 'South West', 'CTRY21CD': 'E92000001', 'CTRY21NM': 'England'}, ignore_index=True)\n",
    "\n",
    "# Remove the small areas (uncombined)\n",
    "tiers = tiers[tiers['LAD21NM'].apply(lambda x: x not in ['Cornwall', 'Isles of Scilly', 'Westminster', 'City of London'])]\n",
    "\n",
    "tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open data files containing nearest neighbour information and process into dictionaries\n",
    "with open('ladsneighbours.json') as json_file:\n",
    "    lads_neigh_raw = json.load(json_file)\n",
    "lads_neigh = {}\n",
    "for i in lads_neigh_raw:\n",
    "    if (lads_neigh_raw[i][0]):\n",
    "        lads_neigh[i] = lads_neigh_raw[i][0][0]\n",
    "    else:\n",
    "        lads_neigh[i] = lads_neigh_raw[i][1]\n",
    "\n",
    "# Add nearest neighbour for combined small areas Cornwall and Isles of Scilly and CoL/Westminster\n",
    "lads_neigh['E06000052/E06000053'] = lads_neigh['E06000052']\n",
    "lads_neigh['E09000001/E09000033'] = lads_neigh['E09000033']\n",
    "\n",
    "countyneighbourdf = pd.read_csv('countyboundaries.csv')\n",
    "county_neigh = {}\n",
    "for i in countyneighbourdf.index:\n",
    "    countycodelist = countyneighbourdf.iloc[i]['neighbours'].split(\",\")\n",
    "    countylengthlist = countyneighbourdf.iloc[i]['lengths'].split(\",\")\n",
    "    zipped = list(zip(countycodelist, countylengthlist))\n",
    "    zipped = [i for i in zipped if i[0][:3] != \"E08\"]\n",
    "    zipped = sorted(zipped, reverse=True, key= lambda x: int(x[1]))\n",
    "    county_neigh[countyneighbourdf.iloc[i]['CTYUA21CD']] = zipped[0][0]\n",
    "\n",
    "# Add nearest neighbours for met counties as they weren't included in boudary data\n",
    "county_neigh['E11000001'] = 'E10000017'\n",
    "county_neigh['E11000002'] = 'E10000017'\n",
    "county_neigh['E11000003'] = 'E10000007'\n",
    "county_neigh['E11000007'] = 'E06000057'\n",
    "county_neigh['E11000005'] = 'E10000031'\n",
    "county_neigh['E11000006'] = 'E10000023'\n",
    "county_neigh['E13000001'] = 'E13000002'\n",
    "county_neigh['E13000002'] = 'E13000001'\n",
    "# Add nearest neighbour for combined Cornwall and Isles of Scilly\n",
    "county_neigh['E06000052/E06000053'] = county_neigh['E06000052']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and process data on statistical similarity\n",
    "similars = {}\n",
    "similar_raw = pd.read_csv('./LAD_MAY_2021_EW_Adjacency_Matrix.csv')\n",
    "for i in similar_raw.index:\n",
    "    similars[similar_raw.iloc[i]['LAD21CD']] = [similar_raw.iloc[i]['LAD1CD'],similar_raw.iloc[i]['LAD2CD'],similar_raw.iloc[i]['LAD3CD'],similar_raw.iloc[i]['LAD4CD']]\n",
    "\n",
    "similars['E06000052/E06000053'] = similars['E06000052']\n",
    "similars['E09000001/E09000033'] = similars['E09000033']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE THE EMPTY OBJECTS FOR EACH PLACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to find a statistically similar area\n",
    "def get_similar(code):\n",
    "    # Create a list of similar areas\n",
    "    theseSimilars = similars[code]\n",
    "    # Get rid of NaNs for the list of similars\n",
    "    theseSimilars = [i for i in theseSimilars if i == i]\n",
    "\n",
    "    # Filter out codes for Scotland and NI\n",
    "    theseSimilars = [i for i in theseSimilars if i[0] not in ['S', 'N']]\n",
    "\n",
    "    # Remove small areas\n",
    "    theseSimilars = [i for i in theseSimilars if i not in ['E09000001', 'E09000033', 'E06000053', 'E06000052']]\n",
    "\n",
    "    # Create variable for most similar area\n",
    "    if len(theseSimilars) > 0:\n",
    "        similar = theseSimilars[0]\n",
    "    else:\n",
    "        similar = None\n",
    "\n",
    "    # If the most similar area is also the nearest area, then chose another area\n",
    "    if similar == las[nameLA]['near']:\n",
    "        # If there's at least two similar areas reselect area\n",
    "        if len(theseSimilars)>1:\n",
    "            similar = theseSimilars[1]\n",
    "        else:\n",
    "            similar = None\n",
    "\n",
    "    return similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and object to populate with each area's data\n",
    "las = {}\n",
    "counties = {}\n",
    "regions = {}\n",
    "countries = {}\n",
    "\n",
    "# Iterate throough index of LA df\n",
    "for i in tiers.index:\n",
    "\n",
    "    # Create a variable which is an iterated row of the df\n",
    "    row = tiers.loc[i]\n",
    "\n",
    "    # The name of the area attached to this row\n",
    "    nameLA = row['LAD21NM']\n",
    "    nameCounty = row['CTY21NM']\n",
    "    nameRegion = row['RGN21NM']\n",
    "    nameCountry = row['CTRY21NM']\n",
    "\n",
    "    # Add an object with name and code info and empty nested oobject for data\n",
    "    las[nameLA] = {}\n",
    "    las[nameLA]['name'] = nameLA\n",
    "    las[nameLA]['parent'] = nameRegion\n",
    "    las[nameLA]['country'] = nameCountry\n",
    "    las[nameLA]['code'] = row['LAD21CD']\n",
    "    las[nameLA]['type'] = 'LAD'\n",
    "    las[nameLA]['data'] = {}\n",
    "\n",
    "    counties[nameCounty] = {}\n",
    "    counties[nameCounty]['name'] = nameCounty\n",
    "    counties[nameCounty]['parent'] = nameRegion\n",
    "    counties[nameCounty]['country'] = nameCountry\n",
    "    counties[nameCounty]['code'] = row['CTY21CD']\n",
    "    counties[nameCounty]['near'] = county_neigh[row['CTY21CD']]\n",
    "    counties[nameCounty]['type'] = 'County'\n",
    "    counties[nameCounty]['data'] = {}\n",
    "\n",
    "    regions[nameRegion] = {}\n",
    "    regions[nameRegion]['name'] = nameRegion\n",
    "    regions[nameRegion]['parent'] = nameCountry\n",
    "    regions[nameRegion]['country'] = nameCountry\n",
    "    regions[nameRegion]['code'] = row['CTY21CD']\n",
    "    regions[nameRegion]['type'] = 'Region'\n",
    "    regions[nameRegion]['data'] = {}\n",
    "\n",
    "    countries[nameCountry] = {}\n",
    "    countries[nameCountry]['name'] = nameCountry\n",
    "    countries[nameCountry]['code'] = row['CTRY21CD']\n",
    "    countries[nameCountry]['type'] = 'Country'\n",
    "    countries[nameCountry]['data'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PROCESSING BEGINS BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIST OF ALL TOPICS AND BOTH YEARS\n",
    "topics = ['care',\n",
    " 'religion',\n",
    " 'ethnicity',\n",
    " 'health',\n",
    " 'economic',\n",
    " 'household',\n",
    " 'marital',\n",
    " 'hours',\n",
    " 'tenure',\n",
    " 'disability',\n",
    " 'national',\n",
    " 'welsh',\n",
    " 'population',\n",
    " 'density',\n",
    " 'age10yr',\n",
    " 'agemed']\n",
    "years = ['2011', '2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_small(df):\n",
    "    cityolondon = df[df['Area Name'] == 'City of London']\n",
    "    westmin = df[df['Area Name'] == 'Westminster']\n",
    "\n",
    "    cityolondon = cityolondon.drop(['Area Code', 'Area Name'], axis=1)\n",
    "    westmin = westmin.drop(['Area Code', 'Area Name'], axis=1)\n",
    "\n",
    "    cityolondon = cityolondon.reset_index(drop=True)\n",
    "    westmin = westmin.reset_index(drop=True)\n",
    "\n",
    "    colandwest = cityolondon.add(westmin, fill_value=0)\n",
    "    colandwest['Area Code'] = 'E09000001/E09000033'\n",
    "    colandwest['Area Name'] = 'City of London/Westminster'\n",
    "\n",
    "    df = df.append(colandwest)\n",
    "\n",
    "    cornwall = df[df['Area Name'] == 'Cornwall']\n",
    "    scilly = df[df['Area Name'] == 'Isles of Scilly']\n",
    "\n",
    "    cornwall = cornwall.drop(['Area Code', 'Area Name'], axis=1)\n",
    "    scilly = scilly.drop(['Area Code', 'Area Name'], axis=1)\n",
    "\n",
    "    cornwall = cornwall.reset_index(drop=True)\n",
    "    scilly = scilly.reset_index(drop=True)\n",
    "\n",
    "    cornandscilly = cornwall.add(scilly, fill_value=0)\n",
    "    cornandscilly['Area Code'] = 'E06000052/E06000053'\n",
    "    cornandscilly['Area Name'] = 'Cornwall/Isles of Scilly'\n",
    "\n",
    "    df = df.append(cornandscilly)\n",
    "\n",
    "    df = df[df['Area Name'].apply(lambda x: x not in ['Westminster', 'City of London', 'Cornwall', 'Isles of Scilly'])]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object that will hold all the dfs for all las in an indexable way\n",
    "data_las = {}\n",
    "data_counties = {}\n",
    "data_regions = {}\n",
    "data_countries = {}\n",
    "\n",
    "for topic in topics:\n",
    "    for year in years:\n",
    "\n",
    "        # Read a csv\n",
    "        df = pd.read_csv(\"./\"+topic+\"_\"+year+\".csv\")\n",
    "\n",
    "        # For some reason some areas have an astrix in the title\n",
    "        # df['Area Name'] = df['Area Name'].str.replace(\"*\", \"\")\n",
    "        df['Area Name'] = df['Area Name'].str.replace(\"\\(Met County\\)\", \"\").str.replace(\"()\", \"\").str.strip() \n",
    "\n",
    "        # Merge data for small areas\n",
    "        df = merge_small(df)\n",
    "\n",
    "        # Create a df including only LAs\n",
    "        data_las[topic+\"_\"+year] = df[df['Area Name'].apply(lambda x: x in las.keys())]\n",
    "\n",
    "        # Create a df including only counties\n",
    "        data_counties[topic+\"_\"+year] = df[df['Area Name'].apply(lambda x: x in counties.keys())]\n",
    "\n",
    "        # Reformat Captialised textfor regions and countries\n",
    "        df['Area Name'] = df['Area Name'].apply(lambda x: x.title().replace(\" And \", \" and \").replace(\" Of \", \" of \"))\n",
    "\n",
    "        # Create df for regions\n",
    "        data_regions[topic+\"_\"+year] = df[df['Area Name'].apply(lambda x: x in regions.keys())]\n",
    "\n",
    "        # Create df for regions\n",
    "        data_countries[topic+\"_\"+year] = df[df['Area Name'].apply(lambda x: x in countries.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These variables hold the relevant data tables and the objects that will be populated with the data, indexible by \n",
    "geog_tables = {'las': data_las, 'counties': data_counties, 'regions': data_regions, 'countries': data_countries}\n",
    "geog_objects = {'las': las, 'counties': counties, 'regions': regions, 'countries': countries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_data(name, geog):\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    for topic in topics:\n",
    "\n",
    "        # Create object for this topic\n",
    "        data[topic] = {}\n",
    "        data[topic]['value'] = {}\n",
    "        data[topic]['perc'] = {}\n",
    "\n",
    "        for year in years:\n",
    "\n",
    "            # Find table corresponding to topic and year\n",
    "            table = geog_tables[geog][topic+'_'+year]\n",
    "\n",
    "            row = table[table['Area Name'] == name].iloc[0]\n",
    "\n",
    "            # Find the row of the table relating to the area of iteration\n",
    "            row = table[table['Area Name'] == name].iloc[0]\n",
    "\n",
    "            # Transform row into dictionary\n",
    "            row = row.to_dict()\n",
    "\n",
    "            # Delete unneeded values\n",
    "            del row['Area Code']\n",
    "            del row['Area Name']\n",
    "\n",
    "            # Assign to main data object\n",
    "            data[topic]['value'][year] = row\n",
    "\n",
    "            # Calculate percentages: this calcualtion assumes that each figure combines to make a total\n",
    "            perc = {i: round(row[i]/sum(row.values()), 5) for i in row}\n",
    "            data[topic]['perc'][year] = perc\n",
    "\n",
    "        for value_perc in ['value', 'perc']:\n",
    "            # Calculate percentage point changes\n",
    "            ob2 = data[topic][value_perc]['2021']\n",
    "            ob1 = data[topic][value_perc]['2011']\n",
    "            percob = {i: round(ob2[i] - ob1[i], 5) for i in ob2}\n",
    "            data[topic][value_perc]['change'] = percob\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDING VALUE DATA FOR EACH TOPIC AND YEAR\n",
    "\n",
    "for name in las.keys():\n",
    "    las[name]['data'] = find_data(name, 'las')\n",
    "\n",
    "for name in counties.keys():\n",
    "    counties[name]['data'] = find_data(name, 'counties')\n",
    "\n",
    "for name in regions.keys():\n",
    "     regions[name]['data'] = find_data(name, 'regions')\n",
    "\n",
    "for name in countries.keys():\n",
    "     countries[name]['data'] = find_data(name, 'countries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in a raw index and outputs a rank\n",
    "def process_rank(raw_rank, group_size):\n",
    "    half_group = round(group_size/2)\n",
    "    rank = raw_rank+1\n",
    "\n",
    "    # If ranked in the bottom half of the group the number is given a negative number. So the last will be -1, second last -2\n",
    "    if rank > half_group:\n",
    "        rank = (1+(group_size-rank))*-1\n",
    "\n",
    "    return rank\n",
    "\n",
    "def create_ranks(name, topic, geog, hier, value_perc):\n",
    "    places = geog_objects[geog]\n",
    "    ob = {}\n",
    "    for type in ['2011', '2021', 'change']:\n",
    "        ob[type] = {}\n",
    "        for var in places[name]['data'][topic][value_perc][type].keys():\n",
    "\n",
    "            # Find the value of the data that is being ranked\n",
    "            this_data = places[name]['data'][topic][value_perc][type][var]\n",
    "\n",
    "            # Create list of values. If regional rank then filter by areas that share the same parent or country\n",
    "            if hier == 'regional':\n",
    "                group_data = [places[i]['data'][topic][value_perc][type][var] for i in places if places[i]['parent'] == places[name]['parent']]\n",
    "            else:\n",
    "                group_data = [places[i]['data'][topic][value_perc][type][var] for i in places if places[i]['country'] == places[name]['country']]\n",
    "            group_size = len(group_data)\n",
    "\n",
    "            # Sort the data then find the index of the data point we are ranking\n",
    "            group_data.sort()\n",
    "            raw_rank = group_data.index(this_data)\n",
    "\n",
    "            # Process the index into a rank and add to the object that will be outputted\n",
    "            ob[type][var] = process_rank(raw_rank, group_size)\n",
    "            \n",
    "    return ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDING PERCENTAGE DATA FOR EACH TOPIC AND YEAR - NOT NEEDED FOR REGIONS AND COUNTRIES\n",
    "\n",
    "for name in las.keys():\n",
    "    for topic in topics:\n",
    "        las[name]['data'][topic]['perc_rank'] = create_ranks(name, topic, 'las', 'national', 'perc')\n",
    "        las[name]['data'][topic]['perc_rank_local'] = create_ranks(name, topic, 'las', 'regional', 'perc')\n",
    "        las[name]['data'][topic]['value_rank'] = create_ranks(name, topic, 'las', 'national', 'value')\n",
    "        las[name]['data'][topic]['value_rank_local'] = create_ranks(name, topic, 'las', 'regional', 'value')\n",
    "\n",
    "\n",
    "for name in counties.keys():\n",
    "    for topic in topics:\n",
    "        counties[name]['data'][topic]['perc_rank'] = create_ranks(name, topic, 'counties', 'national', 'perc')\n",
    "        counties[name]['data'][topic]['perc_rank_local'] = create_ranks(name, topic, 'counties', 'regional', 'perc')\n",
    "        counties[name]['data'][topic]['value_rank'] = create_ranks(name, topic, 'counties', 'national', 'value')\n",
    "        counties[name]['data'][topic]['value_rank_local'] = create_ranks(name, topic, 'counties', 'regional', 'value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find each LA and county's near and similar areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is done after first iteration to point to other objects in dictionary\n",
    "for i in tiers.index:\n",
    "\n",
    "    # Create a variable which is an iterated row of the df\n",
    "    row = tiers.loc[i]\n",
    "\n",
    "    # The name of the area attached to this row\n",
    "    nameLA = row['LAD21NM']\n",
    "    nameCounty = row['CTY21NM']\n",
    "\n",
    "    # print(row['LAD21NM'])\n",
    "    # print(row['LAD21CD'])\n",
    "\n",
    "    # las[nameLA]['near'] = lads_neigh[row['LAD21CD']]\n",
    "    las[nameLA]['near'] = [las[i] for i in las if las[i]['code'] == lads_neigh[row['LAD21CD']]][0].copy()\n",
    "    # las[nameLA]['near']['near'] = 'confudsed'\n",
    "    las[nameLA]['near']['near'] = \"\"\n",
    "    del las[nameLA]['near']['near']\n",
    "    las[nameLA]['near']['similar'] = \"\"\n",
    "    del las[nameLA]['near']['similar']\n",
    "\n",
    "    # las[nameLA]['similar'] = get_similar(row['LAD21CD'])\n",
    "    if get_similar(row['LAD21CD']):\n",
    "        las[nameLA]['similar'] = [las[i] for i in las if las[i]['code'] == get_similar(row['LAD21CD'])][0].copy()\n",
    "        las[nameLA]['similar']['near'] = \"\"\n",
    "        del las[nameLA]['similar']['near']\n",
    "        las[nameLA]['similar']['similar'] = \"\"\n",
    "        del las[nameLA]['similar']['similar']\n",
    "\n",
    "    # counties[nameCounty]['near'] = county_neigh[row['CTY21CD']] \n",
    "    counties[nameCounty]['near'] = [counties[i] for i in counties if counties[i]['code'] == county_neigh[row['CTY21CD']]][0].copy()\n",
    "    counties[nameCounty]['near']['near'] = \"\"\n",
    "    del counties[nameCounty]['near']['near']\n",
    "    counties[nameCounty]['near']['similar'] = \"\"\n",
    "    del counties[nameCounty]['near']['similar']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is the story finding section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a stories array for each area\n",
    "for name in las:\n",
    "    place = las[name]\n",
    "    stories = []\n",
    "    for a in place['data'].keys():\n",
    "        for d in place['data'][a]['perc']['change'].keys():\n",
    "            if a in ['population', 'agemed']:\n",
    "                b = 'value'\n",
    "            else:\n",
    "                b = 'perc'\n",
    "            stories.append({\n",
    "                'label': a+'_'+b+'_change'+'_'+d, \n",
    "                'locRank': place['data'][a][b+'_rank_local']['change'][d], \n",
    "                'natRank': place['data'][a][b+'_rank']['change'][d], \n",
    "                '2011': place['data'][a][b]['2011'][d],\n",
    "                '2021': place['data'][a][b]['2021'][d],\n",
    "                'change': place['data'][a][b]['change'][d],\n",
    "                'perc_cha': 100*(place['data'][a][b]['change'][d]/place['data'][a][b]['2011'][d])\n",
    "            })\n",
    "    place['stories'] = stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function which outputs 1.0 for any positive number and -1.0 for any negative number\n",
    "sign = lambda x: math.copysign(1, x)\n",
    "sign(-9.7)\n",
    "\n",
    "# A function which takes in a list of stories and combines the 'type' lists of any repeated variables and gets rid of the duplcate\n",
    "def combinestories(stories):\n",
    "    stories2 = []\n",
    "    for s in stories:\n",
    "        if s['label'] in [i['label'] for i in stories2]:\n",
    "            index = next((i for i, item in enumerate(stories2) if item['label'] == s['label']), -1)\n",
    "            stories2[index]['type'] = stories2[index]['type'] + s['type']\n",
    "        else:\n",
    "            stories2.append(s)\n",
    "\n",
    "    return stories2\n",
    "\n",
    "# Functions that find regional and national equivelent to a local data point\n",
    "def reg(story):\n",
    "    s=story['label'].split(\"_\")\n",
    "    if len(s)>4:\n",
    "        s[3] = s[3] + \"_\" + s[4]\n",
    "    return region['data'][s[0]][s[1]][s[2]][s[3]]\n",
    "\n",
    "def cou(i):\n",
    "    s=i['label'].split(\"_\")\n",
    "    if len(s)>4:\n",
    "        s[3] = s[3] + \"_\" + s[4]\n",
    "    return country['data'][s[0]][s[1]][s[2]][s[3]]\n",
    "\n",
    "def simi(i):\n",
    "    s=i['label'].split(\"_\")\n",
    "    if len(s)>4:\n",
    "        s[3] = s[3] + \"_\" + s[4]\n",
    "    return similar['data'][s[0]][s[1]][s[2]][s[3]]\n",
    "\n",
    "def near(i):\n",
    "    s=i['label'].split(\"_\")\n",
    "    if len(s)>4:\n",
    "        s[3] = s[3] + \"_\" + s[4]\n",
    "    return nearby['data'][s[0]][s[1]][s[2]][s[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in las:\n",
    "    place = las[name]\n",
    "    region = regions[place['parent']]\n",
    "    country = countries[place['country']]\n",
    "    # Skip similar-area based stories if this LA doesn't have a similar area\n",
    "    if 'similar' in place:\n",
    "        similar = place['similar']\n",
    "    nearby = place['near']\n",
    "\n",
    "    # Create a list of objects ordered by the size of difference between regional and local change\n",
    "    regDiff = [(i, {'otherchange': reg(i), 'dif': i['change']-reg(i)}) for i in place['stories']]\n",
    "    couDiff = [(i, {'otherchange': cou(i), 'dif': i['change']-cou(i)}) for i in place['stories']]\n",
    "    if 'similar' in place:\n",
    "        simiDiff = [(i, {'otherchange': simi(i), 'dif': i['change']-simi(i)}) for i in place['stories']]\n",
    "    nearDiff = [(i, {'otherchange': near(i), 'dif': i['change']-near(i)}) for i in place['stories']]\n",
    "\n",
    "    # Create list of objects ordered by size of PP change\n",
    "    vallist = sorted(place['stories'], reverse=True, key=lambda x: x['change'])\n",
    "\n",
    "    # Iterate through vallist to find the largest percentage point increase for ethnicity and religion\n",
    "    ethStory = next(filter(lambda x: x['label'].split(\"_\")[0] == 'ethnicity', vallist))\n",
    "    relStory = next(filter(lambda x: x['label'].split(\"_\")[0] == 'religion', vallist))\n",
    "\n",
    "    # Add the story type descriptor for these two stories\n",
    "    ethStory = [{**ethStory, **{'type':['ethrel']}}]\n",
    "    relStory = [{**relStory, **{'type':['ethrel']}}]\n",
    "\n",
    "    # Remove all religion and ethnicity variables from our original story list and add the two stories pre-selected\n",
    "    place['stories'] = [i for i in place['stories'] if (i['label'].split(\"_\")[0]!='religion') & (i['label'].split(\"_\")[0]!='ethnicity')]+ethStory+relStory\n",
    "\n",
    "    # This records the story type for each variable in our stories list\n",
    "    stories = []\n",
    "    if (country['name']=='Wales'):\n",
    "        stories=stories+[{**i, **{'type':['welsh']}} for i in place['stories'] if i['label'] == 'welsh_perc_change_Speaks Welsh']\n",
    "    stories+[{**i, **{'type':['pop']}} for i in place['stories'] if i['label'] == 'population_value_change_Population']\n",
    "    stories=stories+[{**i, **{'type':['size']}} for i in place['stories'] if ((abs(i['change'])/abs(i['2011'])>0.2)&(abs(i['change']) > 1))]\n",
    "    stories=stories+[{**i, **{'type':['locRank']}} for i in place['stories'] if (abs(i['locRank']) < 4)&(abs(i['change']) > 0.5)]\n",
    "    stories=stories+[{**i, **{'type':['natRank']}} for i in place['stories'] if (abs(i['natRank']) < 4)&(abs(i['change']) > 0.5)]\n",
    "    stories=stories+[{**i[0], **{'type':['couBuck']}} for i in couDiff if ((abs(i[1]['otherchange'])>1) & (abs(i[0]['change'])>1) & (sign(i[1]['otherchange'])!=sign(i[0]['change'])))]\n",
    "    stories=stories+[{**i[0], **{'type':['regBuck']}} for i in regDiff if ((abs(i[1]['otherchange'])>1) & (abs(i[0]['change'])>1) & (sign(i[1]['otherchange'])!=sign(i[0]['change'])))]\n",
    "    stories=stories+[{**i[0], **{'type':['couDiff']}} for i in couDiff if ((abs(i[1]['dif'])>2) & (sign(i[1]['otherchange'])==sign(i[0]['change'])))]\n",
    "    stories=stories+[{**i[0], **{'type':['regDiff']}} for i in regDiff if ((abs(i[1]['dif'])>2) & (sign(i[1]['otherchange'])==sign(i[0]['change'])))]\n",
    "    stories=stories+[{**i[0], **{'type':['nearDiff']}} for i in nearDiff if ((abs(i[1]['dif'])>2) & (sign(i[1]['otherchange'])==sign(i[0]['change'])))]\n",
    "    if 'similar' in place:\n",
    "        stories=stories+[{**i[0], **{'type':['simiDiff']}} for i in simiDiff if ((abs(i[1]['dif'])>2) & (sign(i[1]['otherchange'])==sign(i[0]['change'])))]\n",
    "    stories=stories+[{**i, **{'type':['general']}} for i in place['stories']]\n",
    "    stories = combinestories(stories)\n",
    "\n",
    "    # This section puts stories in order based on how notable each variable is\n",
    "    stories = sorted(stories, reverse=True, key=lambda x: abs(x['locRank'])<4)\n",
    "    stories = sorted(stories, reverse=True, key=lambda x: abs(x['natRank'])<4)\n",
    "    stories = sorted(stories, reverse=True, key=lambda x: abs(x['locRank'])<3)\n",
    "    stories = sorted(stories, reverse=True, key=lambda x: abs(x['natRank'])<3)\n",
    "    stories = sorted(stories, reverse=True, key=lambda x: x['type']=='regBuck')\n",
    "    stories = sorted(stories, reverse=True, key=lambda x: x['type']=='couBuck')\n",
    "    stories = sorted(stories, reverse=True, key=lambda x: x['label']=='welsh_perc_change_Speaks Welsh')\n",
    "    stories = sorted(stories, reverse=True, key=lambda x: x['label']=='agemed_value_change_Median Age')\n",
    "    stories = sorted(stories, reverse=True, key=lambda x: x['label']=='population_value_change_Population')\n",
    "\n",
    "    # Remove stories from topics that have appeared higher up in the story list\n",
    "    stories_uniquetopic = []\n",
    "    dontInc = ['density', 'age10yr']\n",
    "    for story in stories:\n",
    "        if story['label'].split(\"_\")[0] not in dontInc:\n",
    "            stories_uniquetopic.append(story)\n",
    "            dontInc.append(story['label'].split(\"_\")[0])\n",
    "\n",
    "    place['stories'] = stories_uniquetopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'population_value_change_Population',\n",
       "  'locRank': -5,\n",
       "  'natRank': -33,\n",
       "  '2011': 80679,\n",
       "  '2021': 111350,\n",
       "  'change': 30671,\n",
       "  'perc_cha': 38.01608844928668,\n",
       "  'type': ['size', 'couBuck', 'regDiff', 'general']},\n",
       " {'label': 'agemed_value_change_Median Age',\n",
       "  'locRank': -11,\n",
       "  'natRank': -116,\n",
       "  '2011': 15049,\n",
       "  '2021': 21442,\n",
       "  'change': 6393,\n",
       "  'perc_cha': 42.481227988570666,\n",
       "  'type': ['size', 'couDiff', 'regDiff', 'nearDiff', 'simiDiff', 'general']},\n",
       " {'label': 'welsh_perc_change_Speaks Welsh',\n",
       "  'locRank': -13,\n",
       "  'natRank': -121,\n",
       "  '2011': 0.53711,\n",
       "  '2021': 0.55892,\n",
       "  'change': 0.02181,\n",
       "  'perc_cha': 4.060620729459515,\n",
       "  'type': ['general']},\n",
       " {'label': 'economic_perc_change_Economically inactive: Looking after home or family',\n",
       "  'locRank': 2,\n",
       "  'natRank': 12,\n",
       "  '2011': 0.11969,\n",
       "  '2021': 0.0746,\n",
       "  'change': -0.04509,\n",
       "  'perc_cha': -37.6723201604144,\n",
       "  'type': ['general']},\n",
       " {'label': 'household_perc_change_Single family household: Married or civil partnership couple: No children',\n",
       "  'locRank': -2,\n",
       "  'natRank': -31,\n",
       "  '2011': 0.06324,\n",
       "  '2021': 0.08791,\n",
       "  'change': 0.02467,\n",
       "  'perc_cha': 39.0101201771031,\n",
       "  'type': ['general']},\n",
       " {'label': 'tenure_perc_change_Private rented: Other private rented',\n",
       "  'locRank': 1,\n",
       "  'natRank': 19,\n",
       "  '2011': 0.15226,\n",
       "  '2021': 0.09197,\n",
       "  'change': -0.06029,\n",
       "  'perc_cha': -39.59674241429134,\n",
       "  'type': ['general']},\n",
       " {'label': 'disability_perc_change_Disabled under the Equality Act: Day-to-day activities limited a lot',\n",
       "  'locRank': 3,\n",
       "  'natRank': 40,\n",
       "  '2011': 0.2647,\n",
       "  '2021': 0.20789,\n",
       "  'change': -0.05681,\n",
       "  'perc_cha': -21.46203248961088,\n",
       "  'type': ['general']},\n",
       " {'label': 'care_perc_change_Not a carer',\n",
       "  'locRank': -14,\n",
       "  'natRank': -120,\n",
       "  '2011': 0.15035,\n",
       "  '2021': 0.16065,\n",
       "  'change': 0.0103,\n",
       "  'perc_cha': 6.850681742600598,\n",
       "  'type': ['general']},\n",
       " {'label': 'health_perc_change_Very good health',\n",
       "  'locRank': -5,\n",
       "  'natRank': -32,\n",
       "  '2011': 0.31187,\n",
       "  '2021': 0.36791,\n",
       "  'change': 0.05604,\n",
       "  'perc_cha': 17.96902555551993,\n",
       "  'type': ['general']},\n",
       " {'label': 'marital_perc_change_Single never married or in a civil partnership',\n",
       "  'locRank': 8,\n",
       "  'natRank': 99,\n",
       "  '2011': 0.17172,\n",
       "  '2021': 0.15068,\n",
       "  'change': -0.02104,\n",
       "  'perc_cha': -12.252504076403445,\n",
       "  'type': ['general']},\n",
       " {'label': 'hours_perc_change_Part-time: 15 hours or less worked',\n",
       "  'locRank': -12,\n",
       "  'natRank': 131,\n",
       "  '2011': 0.24038,\n",
       "  '2021': 0.22462,\n",
       "  'change': -0.01576,\n",
       "  'perc_cha': -6.556285880688908,\n",
       "  'type': ['general']},\n",
       " {'label': 'national_perc_change_British only identity',\n",
       "  'locRank': -14,\n",
       "  'natRank': 123,\n",
       "  '2011': 0.04348,\n",
       "  '2021': 0.0403,\n",
       "  'change': -0.00318,\n",
       "  'perc_cha': -7.313707451701933,\n",
       "  'type': ['general']},\n",
       " {'label': 'ethnicity_perc_change_Asian, Asian British or Asian Welsh',\n",
       "  'locRank': -4,\n",
       "  'natRank': -34,\n",
       "  '2011': 0.15453,\n",
       "  '2021': 0.21062,\n",
       "  'change': 0.05609,\n",
       "  'perc_cha': 36.297159127677475,\n",
       "  'type': ['general']},\n",
       " {'label': 'religion_perc_change_Hindu',\n",
       "  'locRank': -4,\n",
       "  'natRank': -48,\n",
       "  '2011': 0.10241,\n",
       "  '2021': 0.13578,\n",
       "  'change': 0.03337,\n",
       "  'perc_cha': 32.584708524558145,\n",
       "  'type': ['general']}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place['stories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an empty array where selected stories will be passed\n",
    "# newStories = []\n",
    "\n",
    "# # Iterate through each area's list of stories\n",
    "# for story in place['stories']:\n",
    "\n",
    "#     # Create array from story label and format last point incase variable includes '_'\n",
    "#     s=story['label'].split(\"_\")\n",
    "#     if len(s)>4:\n",
    "#         s[3] = s[3] + \"_\" + s[4]\n",
    "\n",
    "#     # Don't add Welsh story for non-Welsh areas\n",
    "#     if (s[0]=='welsh') & (place['parent'] != 'Wales'):\n",
    "#         pass\n",
    "\n",
    "#     else:\n",
    "#         newStories.append(story)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter out priority list by subject\n",
    "# for lad in las:\n",
    "#     newStories = []\n",
    "#     for story in lad['stories']:\n",
    "#         s=story['label'].split(\"_\")\n",
    "#         if len(s)>4:\n",
    "#             s[3] = s[3] + \"_\" + s[4]\n",
    "#         if (s[0]=='welsh') & (lad['parents'][0]['name'] != 'Wales'):\n",
    "#             pass\n",
    "#         else:\n",
    "#             story['2011'] = [i for i in lad['Priorities'] if i['label']==s[0]+'_'+s[1]+'_2011_'+s[3]][0]['value']\n",
    "#             story['perccha'] = round(100*((story['value']+0.001)/([i for i in lad['Priorities'] if i['label']==s[0]+'_'+s[1]+'_2001_'+s[3]][0]['value']+0.001)),2)\n",
    "#             newStories.append(story)\n",
    "#         if (s[2]!=\"change\"):\n",
    "#             newStories.append(story)\n",
    "#     lad['stories'] = newStories"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c3aa89ca4d209c971de495120129cb3d674e54ab86ac569af1bfb76a7040f0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
